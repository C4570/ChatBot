{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eX_WeAfF-IEQ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install spacy\n",
        "!pip install PyPDF2\n",
        "!pip install serpapi\n",
        "!pip install chromadb\n",
        "!pip install networkx\n",
        "!pip install unidecode\n",
        "!pip install langchain\n",
        "!pip install fuzzywuzzy\n",
        "!pip install python-docx\n",
        "!pip install python-Levenshtein\n",
        "!pip install langchain-community\n",
        "!pip install sentence-transformers\n",
        "!python -m spacy download es_core_news_md\n",
        "!pip install llama-index-embeddings-huggingface==0.1.1 sentence-transformers==2.3.1 pypdf==4.0.1 langchain==0.1.7 python-decouple==3.8 llm-templates llama-index-readers-file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_txXt-9EAWLo"
      },
      "source": [
        "# Obtención y Carga de Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HcktNbnIP9O",
        "outputId": "defa45bb-83ed-4724-d157-710af4936829"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La carpeta 'Archivos_necesarios' fue descargada con éxito.\n"
          ]
        }
      ],
      "source": [
        "import gdown\n",
        "import os\n",
        "\n",
        "# Link con archivos sobre NLP\n",
        "url = 'https://drive.google.com/drive/folders/1x_DXa3qQZtSaSGjXa3ntycesMABwn2eR?usp=sharing'\n",
        "output_folder = 'Archivos_necesarios'\n",
        "\n",
        "# Verifica si la carpeta ya existe\n",
        "if os.path.exists(output_folder):\n",
        "    print(f\"La carpeta '{output_folder}' ya existe. No se descargará nuevamente.\")\n",
        "else:\n",
        "    # Descarga la carpeta\n",
        "    gdown.download_folder(url, quiet=True, output=output_folder)\n",
        "    print(f\"La carpeta '{output_folder}' fue descargada con éxito.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oRsI9uAzAqHr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "# Carga de PDFs\n",
        "unidad_1 = '/content/Archivos_necesarios/Unidad 1 - Extracción y Procesamiento de Texto.pdf'\n",
        "unidad_2 = '/content/Archivos_necesarios/Unidad 2 - Representación Vectorial de Texto.pdf'\n",
        "unidad_3 = '/content/Archivos_necesarios/Unidad 3 - Procesamiento del Lenguaje.pdf'\n",
        "unidad_4 = '/content/Archivos_necesarios/Unidad 4 - Arquitecturas de Modelos de Lenguaje.pdf'\n",
        "unidad_5 = '/content/Archivos_necesarios/Unidad 5 - Almacenamiento y Representación del Conocimiento.pdf'\n",
        "unidad_6 = '/content/Archivos_necesarios/Unidad 6 - Chatbots y Sistemas de Diálogo.pdf'\n",
        "unidad_7 = '/content/Archivos_necesarios/Unidad 7 - Agentes Autónomos y Sistemas Inteligentes - 2024.pdf'\n",
        "\n",
        "pdfs = [unidad_1, unidad_2, unidad_3, unidad_4, unidad_5, unidad_6, unidad_7]\n",
        "\n",
        "# Carga del archivo CSV\n",
        "ejercicios = pd.read_csv('/content/Archivos_necesarios/ejercicios_nlp_con_embeddings.csv')\n",
        "\n",
        "# Carga del grafo\n",
        "with open(\"/content/Archivos_necesarios/grafo_nlp.pickle\", \"rb\") as f:\n",
        "    G = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTEpUB8VcqCi"
      },
      "source": [
        "# Preprocesamiento de texto, extracción de PDF y split de datos con LangChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QVW7yon-g7y",
        "outputId": "bcbfaea2-bf10-4af8-88e0-2af4320bb8fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fragmentos de la Unidad 1:\n",
            "Fragmento 1: unidad 1 - extracción y procesamiento de texto\n",
            "1. ...\n",
            "Fragmento 2: de las que se puede extraer texto:\n",
            "•documentos de ...\n",
            "Fragmento 3: de noticias, foros de discusión, wikipedia y más.\n",
            "...\n",
            "Fragmento 4: electrónico, así como los asuntos y los encabezado...\n",
            "Fragmento 5: extraídas para análisis de texto.\n",
            "•literatura: los...\n",
            "Fragmento 6: datos.\n",
            "formatos y fuentes de texto\n",
            "en el mundo de ...\n",
            "Fragmento 7: semi-estructurados y no estructurados, y pueden es...\n",
            "Fragmento 8: formato de texto, como negrita, cursiva, colores, ...\n",
            "Fragmento 9: contenido del archivo y lo almacenará en la variab...\n",
            "Fragmento 10: codificación diferente, como iso-8859-1 o latin-1\n",
            "...\n",
            "Fragmento 11: estuviera codificado en latin-1, usaríamos encodin...\n",
            "Fragmento 12: utf-8:la cadena en esa codificación posee una long...\n",
            "Fragmento 13: codificarse, y además su codificación puede cambia...\n",
            "Fragmento 14: encabezados, enlaces, imágenes, listas, tablas, et...\n",
            "Fragmento 15: <!\n",
            ">\n",
            "<\n",
            ">\n",
            "<\n",
            ">\n",
            "<\n",
            ">\n",
            "</\n",
            ">\n",
            "</\n",
            ">\n",
            "<\n",
            ">\n",
            "<\n",
            ">\n",
            "</\n",
            ">\n",
            "</\n",
            ">\n",
            "</\n",
            ">\n",
            "...\n",
            "Fragmento 16: 2.<h1> a <h6>: definen los encabezados. <h1> es el...\n",
            "Fragmento 17: 5.<u>: subraya el texto. por ejemplo: <u>este text...\n",
            "Fragmento 18: estas son solo algunas de las muchas etiquetas htm...\n",
            "Fragmento 19: lee todo el contenido del archivo contenido_html =...\n",
            "Fragmento 20: necesitaremos instalar las librerías beautifulsoup...\n",
            "Fragmento 21: preservar ciertos elementos de formato, tendríamos...\n",
            "Fragmento 22: archivo de markdown en python de la misma manera q...\n",
            "Fragmento 23: exto_markdown # imprime el html printhtml\n",
            "(\n",
            ",\n",
            ")\n",
            ":\n",
            "...\n",
            "Fragmento 24: html2text. primero, convertiremos el markdown a ht...\n",
            "Fragmento 25: es en la conversión hignore_links = true # convier...\n",
            "Fragmento 26: html2text).\n",
            "formato pdf\n",
            "el formato de archivo pdf ...\n",
            "Fragmento 27: 1.cabecera: indica la versión del pdf. por ejemplo...\n",
            "Fragmento 28: archivo. esto permite que los lectores de pdf acce...\n",
            "Fragmento 29: •objeto de catálogo: el nodo raíz del árbol, que r...\n",
            "Fragmento 30: •otros objetos: incluyen metadatos, anotaciones (c...\n",
            "Fragmento 31: import pypdf2 # abre el archivo en modo binario de...\n",
            "Fragmento 32: exto extraído printtexto\n",
            "(\n",
            ",\n",
            ")\n",
            ":\n",
            ".\n",
            "(\n",
            ")\n",
            "(\n",
            "(\n",
            ".\n",
            ")\n",
            ")\n",
            ":...\n",
            "Fragmento 33: texto está almacenado como imágenes. en esos casos...\n",
            "Fragmento 34: hacerlo. primero instalamos los paquetes necesario...\n",
            "Fragmento 35: (\n",
            ")\n",
            ",\n",
            "(\n",
            ")\n",
            ":\n",
            ".\n",
            "(\n",
            ".\n",
            "(\n",
            ")\n",
            ",\n",
            ")este código abrirá un arc...\n",
            "Fragmento 36: una vez que tenemos las imágenes, podemos usar una...\n",
            "Fragmento 37: metacreator print\"producer: \" metaproducer print\"s...\n",
            "Fragmento 38: •pymupdf - \n",
            "pymupdf\n",
            "•pytesseract - \n",
            "pytesseract\n",
            "te...\n",
            "Fragmento 39: aquí vemos un ejemplo de cómo hacerlo:\n",
            "# primero i...\n",
            "Fragmento 40: .\n",
            "(\n",
            ")\n",
            ".\n",
            "(\n",
            ",\n",
            ")\n",
            "(\n",
            ")\n",
            "este código abrirá un archivo ll...\n",
            "Fragmento 41: distorsiones. podemos mejorar la precisión del ocr...\n",
            "Fragmento 42: easyocr\n",
            "aquí vemos un ejemplo de cómo extraer text...\n",
            "Fragmento 43: ción del bloque de texto en la imagen, # y la segu...\n",
            "Fragmento 44: texto desde ms word\n",
            "el formato docx es el formato ...\n",
            "Fragmento 45: docx para extraer texto de un archivo docx:\n",
            "from d...\n",
            "Fragmento 46: docx.\n",
            "texto desde imágenes o video\n",
            "para transcribi...\n",
            "Fragmento 47: texto = rrecognize_googleaudio_data printtexto\n",
            ".\n",
            "(...\n",
            "Fragmento 48: speechrecognition.\n",
            "tengamos en cuenta que este cód...\n",
            "Fragmento 49: acentos fuertes, o distorsiones. podremos mejorar ...\n",
            "Fragmento 50: reconocimiento de voz multilingüe, traducción de v...\n",
            "Fragmento 51: estas tareas se representan conjuntamente como una...\n",
            "Fragmento 52: https://colab.research.google.com/github/openai/wh...\n",
            "Fragmento 53: 'text' 'hey there' 'start' 7.58 'duration' 6.13   ...\n",
            "Fragmento 54: texto ofensivo o discriminatorio. una forma de acc...\n",
            "Fragmento 55: twitter. aquí vemos un ejemplo de cómo hacerlo:imp...\n",
            "Fragmento 56: ret authset_access_tokenaccess_token access_token_...\n",
            "Fragmento 57: especificado y imprimirá el texto de cada tweet.\n",
            "n...\n",
            "Fragmento 58: palabras clave, o si queremos obtener tweets de va...\n",
            "Fragmento 59: texto desde wikipedia\n",
            "también es posible extraer t...\n",
            "Fragmento 60: wiki_wikipage\"python_(lenguaje_de_programación)\" #...\n",
            "Fragmento 61: bases de datos pueden incluir texto de diversas fu...\n",
            "Fragmento 62: bases de datos sqlite.\n",
            "2.psycopg2: psycopg es el a...\n",
            "Fragmento 63: múltiples motores de bases utilizando programación...\n",
            "Fragmento 64: a results = cfetchall # imprime los resultados for...\n",
            "Fragmento 65: debemos tener en cuenta que este es solo un ejempl...\n",
            "Fragmento 66: import pandas as pd # lee el archivo de excel df =...\n",
            "Fragmento 67: .\n",
            "(\n",
            ")\n",
            "[\n",
            "]\n",
            "(\n",
            ")\n",
            "texto desde json\n",
            "es común extraer te...\n",
            "Fragmento 68: json para analizar el contenido del archivo. aquí ...\n",
            "Fragmento 69: https://www.example.com/data.json\n",
            "web scraping\n",
            "el ...\n",
            "Fragmento 70: , \n",
            "scrapy, \n",
            "selenium, entre otras.\n",
            "beautifulsoup\n",
            "a...\n",
            "Fragmento 71: ón en cada caso. letra_div = soupfind'section' 'cl...\n",
            "Fragmento 72: #!pip install beautifulsoup4 import requests from ...\n",
            "Fragmento 73: método select de beautifulsoup para encontrar los ...\n",
            "Fragmento 74: .\n",
            "(\n",
            ")\n",
            "(\n",
            ".\n",
            ",\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            ".\n",
            "(\n",
            ".\n",
            ")\n",
            "(\n",
            ")este código abrirá ...\n",
            "Fragmento 75: debemos tener en en cuenta que el web scraping deb...\n",
            "Fragmento 76: en algunos casos se requiere realizar login en una...\n",
            "Fragmento 77: e sesión login_url = 'https://www.ejemplo.com/logi...\n",
            "Fragmento 78: utifulsoupresponsecontent 'html.parser' # extrae e...\n",
            "Fragmento 79: luego realizará una solicitud get a la página prot...\n",
            "Fragmento 80: requests\n",
            "tengamos en cuenta que este es un ejemplo...\n",
            "Fragmento 81: mechanize\n",
            "parseo de texto\n",
            "\"parsear\" es un término ...\n",
            "Fragmento 82: que no nos resulta útil. veamos un caso: supongamo...\n",
            "Fragmento 83: https://raw.githubusercontent.com/govcert-\n",
            "lu/eml_...\n",
            "Fragmento 84: responsetext # busca los boundaries boundary_patte...\n",
            "Fragmento 85: eml_contentsplitboundary_matches0 # usamos el segu...\n",
            "Fragmento 86: {}|$)'formatboundary_quoted part redotall if text_...\n",
            "Fragmento 87: como vemos en el ejemplo, nos valemos de diferente...\n",
            "Fragmento 88: que debemos utilizar otras herramientas para poder...\n",
            "Fragmento 89: objeto beautifulsoup con el contenido de la página...\n",
            "Fragmento 90: 'titleline' in span_childattrs'class' a_link = lis...\n",
            "Fragmento 91: parse). aquí vemos un ejemplo simple:\n",
            "from parse i...\n",
            "Fragmento 92: análisis.\n",
            "aquí vemos un ejemplo más complejo que i...\n",
            "Fragmento 93: (\n",
            ",\n",
            ")\n",
            ",\n",
            ",\n",
            ",\n",
            ",\n",
            "(\n",
            ",\n",
            ",\n",
            ",\n",
            ",\n",
            ")\n",
            "en este ejemplo, el patr...\n",
            "Fragmento 94: ,\n",
            ",\n",
            "(\n",
            ",\n",
            ")\n",
            "(\n",
            ")\n",
            "(\n",
            ")\n",
            "(\n",
            ")\n",
            "de esta manera podemos extra...\n",
            "Fragmento 95: del texto.\n",
            "el procesamiento del texto es un paso c...\n",
            "Fragmento 96: donde aprenderemos cómo eliminar texto innecesario...\n",
            "Fragmento 97: para aplicar técnicas de procesamiento de lenguaje...\n",
            "Fragmento 98: conversión a minúsculas\n",
            "la forma más sencilla de c...\n",
            "Fragmento 99: aprendizaje automático es la nueva electricidad' '...\n",
            "Fragmento 100: [\n",
            ",\n",
            ",\n",
            ",\n",
            ",\n",
            ",\n",
            ",\n",
            ",\n",
            "]\n",
            ".\n",
            "(\n",
            "{\n",
            ":\n",
            "}\n",
            ")\n",
            "[\n",
            "]\n",
            "[\n",
            "]\n",
            ".\n",
            "(\n",
            ":\n",
            ".\n",
            "(\n",
            ")\n",
            "...\n",
            "Fragmento 101: .\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ":\n",
            ",\n",
            ":\n",
            "eliminación de puntuación\n",
            "en alg...\n",
            "Fragmento 102: .\n",
            "(\n",
            ",\n",
            ",\n",
            ")\n",
            "(\n",
            ")\n",
            "o usando pandas:\n",
            "import pandas as pd...\n",
            "Fragmento 103: '[^\\w\\s]' ''\n",
            "[\n",
            ",\n",
            ",\n",
            ",\n",
            ",\n",
            ",\n",
            ",\n",
            ",\n",
            "]\n",
            ".\n",
            "(\n",
            "{\n",
            ":\n",
            "}\n",
            ")\n",
            "[\n",
            "]\n",
            "[\n",
            "]...\n",
            "Fragmento 104: contexto y del problema específico que estés trata...\n",
            "Fragmento 105: \"cafe\". en conjuntos de datos que provienen de múl...\n",
            "Fragmento 106: ''joinc for c in nfkd_form if not unicodedatacombi...\n",
            "Fragmento 107: la idea es usar la función del módulo unicodedata ...\n",
            "Fragmento 108: cadena resultante.\n",
            "más información sobre forma can...\n",
            "Fragmento 109: más importantes. por ejemplo, en un motor de búsqu...\n",
            "Fragmento 110: español. por lo tanto, si eliminamos tales palabra...\n",
            "Fragmento 111: aquí tenemos un ejemplo de cómo podríamos eliminar...\n",
            "Fragmento 112: nueva electricidad' 'habrá menos exageración sobre...\n",
            "Fragmento 113: word for word in word_tokens if wordcasefold not i...\n",
            "Fragmento 114: palabras de parada de una frase. \n",
            "al aplicar casef...\n",
            "Fragmento 115: 0 introducción nlp 1 probable útil personas 2 mach...\n",
            "Fragmento 116: eliminación de la puntuación, la corrección de err...\n",
            "Fragmento 117: sea útil para las personas' 'machine learning es l...\n",
            "Fragmento 118: arización del texto def text_stdinput_text words =...\n",
            "Fragmento 119: )\n",
            "[\n",
            "]\n",
            ":\n",
            ".\n",
            "(\n",
            ",\n",
            ",\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            ":\n",
            "[\n",
            ".\n",
            "(\n",
            ")\n",
            "]\n",
            ".\n",
            "(\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            "[\n",
            "...\n",
            "Fragmento 120: de nuevo en un texto. finalmente, aplicamos esta f...\n",
            "Fragmento 121: tengamos en cuenta que las abreviaturas deben mane...\n",
            "Fragmento 122: otros idiomas como el español. para la corrección ...\n",
            "Fragmento 123: spellchecker # configurar el corrector ortográfico...\n",
            "Fragmento 124: lenguaje' 'me gusta este livro' 'quiero más livros...\n",
            "Fragmento 125: df'tweet'applylambda x ' 'joinspell_2correctioni i...\n",
            "Fragmento 126: tokenización de texto\n",
            "la tokenización de texto se ...\n",
            "Fragmento 127: se puede hacer la tokenización de palabras usando ...\n",
            "Fragmento 128: herramienta!' 'python es un buen lenguaje' 'me gus...\n",
            "Fragmento 129: ndo textblob:' for i tokens in enumeratetokenized_...\n",
            "Fragmento 130: 'es' 'la' 'mejor' 'herramienta' '!' texto 6 'pytho...\n",
            "Fragmento 131: 'la' 'ia' 'y' 'más' 'acción' 'en' 'adelante' texto...\n",
            "Fragmento 132: ,\n",
            ",\n",
            ",\n",
            ",\n",
            "]\n",
            ":\n",
            "[\n",
            ",\n",
            ",\n",
            ",\n",
            ",\n",
            "]\n",
            ":\n",
            "[\n",
            ",\n",
            ",\n",
            ",\n",
            "]\n",
            ":\n",
            "[\n",
            ",\n",
            ",\n",
            ",\n",
            ",\n",
            "]\n",
            "...\n",
            "Fragmento 133: formas (por ejemplo, singular, plural, verbos en d...\n",
            "Fragmento 134: .\n",
            ".\n",
            "(\n",
            ")\n",
            "[\n",
            ".\n",
            "(\n",
            ")\n",
            "(\n",
            ")\n",
            "]\n",
            "(\n",
            ")\n",
            "y el resultado será:\n",
            "'el...\n",
            "Fragmento 135: la que pertenece. por lo tanto, aunque es más comp...\n",
            "Fragmento 136: luego podemos realizar la lematización del siguien...\n",
            "Fragmento 137: printlematizado # la salida será: # 'el perro esta...\n",
            "Fragmento 138: 1.eliminarlos: si los emojis y emoticonos no son r...\n",
            "Fragmento 139: análisis.\n",
            "3.tratarlos como palabras: también podem...\n",
            "Fragmento 140: import emoji text = \"me encanta programar en pytho...\n",
            "Fragmento 141: .\n",
            ".\n",
            "(\n",
            ")\n",
            "(\n",
            ".\n",
            "(\n",
            ")\n",
            ")\n",
            "(\n",
            ".\n",
            "(\n",
            ")\n",
            ")\n",
            "y el resultado será:'v...\n",
            "Fragmento 142: convert_emojistext return demojireplace_with_desct...\n",
            "Fragmento 143: •análisis de frecuencia de palabras: esto implica ...\n",
            "Fragmento 144: muchas oraciones largas, podría indicar un estilo ...\n",
            "Fragmento 145: contexto en el que se utilizan las palabras.\n",
            "•anál...\n",
            "Fragmento 146: viviendo la vida de alguien más. no dejes que el r...\n",
            "Fragmento 147: las frecuencias print'frecuencia de palabras:' fdi...\n",
            "Fragmento 148: que el ruido de la opinión de los demás acalle tu ...\n",
            "Fragmento 149: ,\n",
            ",\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            ".\n",
            "(\n",
            "(\n",
            ",\n",
            ")\n",
            ",\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            "...\n",
            "Fragmento 150: import nltk from nltkutil import ngrams nltkdownlo...\n",
            "Fragmento 151: .\n",
            ".\n",
            "(\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            "(\n",
            "(\n",
            ",\n",
            ")\n",
            ")\n",
            "(\n",
            "(\n",
            ",\n",
            ")\n",
            ")\n",
            "(\n",
            ")\n",
            "(\n",
            ")\n",
            "(\n",
            ")\n",
            "(\n",
            ")\n",
            "...\n",
            "Fragmento 152: co-ocurren. la co-ocurrencia puede ser medida de v...\n",
            "Fragmento 153: ubicado en el extremo sur de américa del sur. buen...\n",
            "Fragmento 154: res de alta calidad. el país cuenta con una varied...\n",
            "Fragmento 155: y una historia fascinante.\" # divide el texto en o...\n",
            "Fragmento 156: index=vectorizerget_feature_names_out columns=vect...\n",
            "Fragmento 157: .\n",
            ".\n",
            ".\n",
            "(\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            "(\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            "(\n",
            ".\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            ".\n",
            "(\n",
            ".\n",
            "(\n",
            ")\n",
            ",\n",
            "...\n",
            "Fragmento 158: aires 1 0 1 ... 0 0 0 0 0 alta 0 1 0 ... 0 0 0 0 0...\n",
            "Fragmento 159: vastas 1 0 0 0 0 vino 0 0 0 0 0 xx 0 0 0 0 1 últim...\n",
            "Fragmento 160: unidades más pequeñas y manejables, también conoci...\n",
            "Fragmento 161: la consulta del usuario.\n",
            "en el caso de los agentes...\n",
            "Fragmento 162: opcionalmente, si debe haber algún solapamiento en...\n",
            "Fragmento 163: request a la página de wikipedia url = \"https://es...\n",
            "Fragmento 164: .\n",
            ".\n",
            "(\n",
            ")\n",
            "(\n",
            ".\n",
            ",\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            "(\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            "(\n",
            "[\n",
            "]\n",
            ")\n",
            "este códig...\n",
            "Fragmento 165: charactertextsplitter\n",
            "langchain\n",
            "text_splitter = ch...\n",
            "Fragmento 166: utilizaría la segmentación por frases, y hay varia...\n",
            "Fragmento 167: .\n",
            "(\n",
            ")\n",
            "el kit de herramientas de lenguaje natural (...\n",
            "Fragmento 168: :\n",
            "librería\n",
            "langchain\n",
            "nltktextsplittertext = \"...\" ...\n",
            "Fragmento 169: oraciones que puede dividir el texto de manera efi...\n",
            "Fragmento 170: spacytextsplitter(pipeline='es_core_news_sm') docs...\n",
            "Fragmento 171: efecto invernadero aumentó las temperaturas promed...\n",
            "Fragmento 172: más dispersión de enfermedades como dengue.']\n",
            "tamb...\n",
            "Fragmento 173: muy bonito. además, tiene muchos lugares histórico...\n",
            "Fragmento 174: )\n",
            ".\n",
            "(\n",
            ")\n",
            ",\n",
            "(\n",
            ")\n",
            ":\n",
            "(\n",
            "{\n",
            "}\n",
            "{\n",
            "}\n",
            ")\n",
            "y el resultado será:\n",
            "o...\n",
            "Fragmento 175: utilizando un conjunto de separadores. por defecto...\n",
            "Fragmento 176: fragmento deseado. para eso, podríamos usar :\n",
            "recu...\n",
            "Fragmento 177: mundo, especialmente conocido por su vino malbec. ...\n",
            "Fragmento 178: impresionante glaciar perito moreno. argentina ha ...\n",
            "Fragmento 179: .\n",
            "(\n",
            ",\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            ":\n",
            "(\n",
            "{\n",
            "(\n",
            ")\n",
            "}\n",
            "{\n",
            "}\n",
            ")\n",
            "el resultado será:...\n",
            "\n",
            "Fragmentos de la Unidad 2:\n",
            "Fragmento 1: unidad 2 - representación\n",
            "vectorial de texto\n",
            "en el...\n",
            "Fragmento 2: en el procesamiento del lenguaje natural, uno de l...\n",
            "Fragmento 3: one-hot encoding\n",
            "la codificación one-hot es una té...\n",
            "Fragmento 4: tipo de variables que se utilizan para etiquetar u...\n",
            "Fragmento 5: representa con un vector de longitud n, donde la p...\n",
            "Fragmento 6: categóricos para el aprendizaje automático, pero t...\n",
            "Fragmento 7: from sklearnpreprocessing import onehotencoder imp...\n",
            "Fragmento 8: enumeratepalabras printf\"la palabra 'palabra' se c...\n",
            "Fragmento 9: 1 0 0\n",
            "0 1 0\n",
            "0 0 11. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. ...\n",
            "Fragmento 10: import pandas as pd # nuestra frase de trabajo fra...\n",
            "Fragmento 11: codificó como: onehot_encodedilocito_numpy\"\n",
            ".\n",
            "(\n",
            ")\n",
            "...\n",
            "Fragmento 12: nuestro conjunto de datos, contamos cuántas veces ...\n",
            "Fragmento 13: aparece y 'casa' aparece una vez.una de las ventaj...\n",
            "Fragmento 14: como 'el', 'un', 'la', etc., pueden aparecer con m...\n",
            "Fragmento 15: import pandas as pd from sklearnfeature_extraction...\n",
            "Fragmento 16: primimos los vectores de características print\"vec...\n",
            "Fragmento 17: (\n",
            ",\n",
            ".\n",
            "(\n",
            ")\n",
            ")\n",
            "(\n",
            ",\n",
            ".\n",
            "(\n",
            ")\n",
            ")\n",
            ".\n",
            "(\n",
            ".\n",
            "(\n",
            ")\n",
            ",\n",
            ".\n",
            "(\n",
            ")\n",
            ")\n",
            "(\n",
            ")\n",
            "(\n",
            "...\n",
            "Fragmento 18: 'casa' 'el' 'en' 'está' 'gato' 'jardín' 'juega' 'l...\n",
            "Fragmento 19: del lenguaje natural. es una forma de representar ...\n",
            "Fragmento 20: tf-idf se compone de dos componentes:\n",
            "•tf (frecuen...\n",
            "Fragmento 21: documento.\n",
            "tf(t,d)=\n",
            " nmero total de trminos en el ...\n",
            "Fragmento 22: frecuencia de las palabras. es el logaritmo del nú...\n",
            "Fragmento 23: importancia en los cálculos de tf-idf.\n",
            "idf(t,d)=\n",
            "l...\n",
            "Fragmento 24: dimensión es una palabra específica del corpus y e...\n",
            "Fragmento 25: aquí vemos ejemplo de cómo usar tfidfvectorizer de...\n",
            "Fragmento 26: # ajustamos y transformamos nuestro corpus x = vec...\n",
            "Fragmento 27: (\n",
            ")\n",
            "(\n",
            ",\n",
            ".\n",
            "(\n",
            ")\n",
            ")\n",
            "(\n",
            ")\n",
            "(\n",
            ".\n",
            "(\n",
            ")\n",
            ")\n",
            "(\n",
            ")\n",
            "(\n",
            ".\n",
            ")\n",
            "(\n",
            ")\n",
            "(\n",
            ".\n",
            ")\n",
            "...\n",
            "Fragmento 28: idf de cada palabra en cada documento. como result...\n",
            "Fragmento 29: [\n",
            "]\n",
            ":\n",
            "[\n",
            "[\n",
            "]\n",
            "[\n",
            "]\n",
            "[\n",
            "]\n",
            "]\n",
            ":\n",
            "{\n",
            ":\n",
            ",\n",
            ":\n",
            ",\n",
            ":\n",
            ",\n",
            ":\n",
            ",\n",
            ":\n",
            "}\n",
            ":\n",
            "[\n",
            "...\n",
            "Fragmento 30: .  es\n",
            "importante destacar que scikit-learn también...\n",
            "Fragmento 31: . una función de hash es una función que toma una ...\n",
            "Fragmento 32: hash para convertir las características de texto e...\n",
            "Fragmento 33: sklearn. cuando se inicializa un , se puede especi...\n",
            "Fragmento 34: hashingvectorizer\n",
            "hashingvectorizer\n",
            "el proceso de ...\n",
            "Fragmento 35: documentos, y el número de características que use...\n",
            "Fragmento 36: ser un inconveniente si necesitamos interpretar lo...\n",
            "Fragmento 37: creamos el hashingvectorizer vectorizer =\n",
            "hashingv...\n",
            "Fragmento 38: de características utilizando el método transform(...\n",
            "Fragmento 39: 0.4472136 -0.4472136 -0.4472136 0. 0. ] [ 0.5 -0.5...\n",
            "Fragmento 40: hashingvectorizer no proporciona una forma de mape...\n",
            "Fragmento 41: grande.\n",
            "resumen de métodos vectorización\n",
            "si bien h...\n",
            "Fragmento 42: complementación con modelos como naive bayes, regr...\n",
            "Fragmento 43: contexto o la relación entre las palabras.\n",
            "por eje...\n",
            "Fragmento 44: dimensional\n",
            "cuenta la fre\n",
            "ni su relevan\n",
            "count vect...\n",
            "Fragmento 45: en el texto.más comple\n",
            "implementa\n",
            "anteriores.\n",
            "hash...\n",
            "Fragmento 46: independientemente del modelo que usemos, estaremo...\n",
            "Fragmento 47: semántica y las relaciones entre las palabras. gen...\n",
            "Fragmento 48: en un espacio de alta dimensión, donde las palabra...\n",
            "Fragmento 49: \"gato\" a menudo aparecen en contextos similares (c...\n",
            "Fragmento 50: \"mujer\", o que \"caminar\" es la versión en presente...\n",
            "Fragmento 51: (=5). tendríamos un vector de ceros excepto para e...\n",
            "Fragmento 52: ver con el resto (no hay proyección a lo largo de ...\n",
            "Fragmento 53: a partir de los datos.\n",
            "características semánticas\n",
            "...\n",
            "Fragmento 54: significado de cada palabra. si asociamos una esca...\n",
            "Fragmento 55: mismos atributos de género y edad que \"man\", \"woma...\n",
            "Fragmento 56: de números las llamamos vectores . dado que repres...\n",
            "Fragmento 57: similitud de coseno\n",
            "nuestro objetivo es que las pa...\n",
            "Fragmento 58: • ∥a ∥ y ∥b ∥ son las magnitudes (o normas) de los...\n",
            "Fragmento 59: palabras se normalizan para tener una longitud (o ...\n",
            "Fragmento 60: dimensión (por ejemplo, 300 dimensiones para los v...\n",
            "Fragmento 61: significa que son ortogonales (no relacionados), y...\n",
            "Fragmento 62: y tiene la buena propiedad de ser mayor cuando los...\n",
            "Fragmento 63: ada. retorna: - similitud del coseno entre a y b. ...\n",
            "Fragmento 64: su similitud del coseno. el coseno de un ángulo de...\n",
            "Fragmento 65: # supongamos que estos son tus vectores (embedding...\n",
            "Fragmento 66: for name similarity in zipvector_names similaritie...\n",
            "Fragmento 67: https://aman.ai/coursera-nlp/vector-spaces/\n",
            "tipos ...\n",
            "Fragmento 68: de lenguaje o factorización de matrices de co-ocur...\n",
            "Fragmento 69: 2. contexto-dependiente (context-dependent):\n",
            "•a di...\n",
            "Fragmento 70: categorías principales:\n",
            "◦basados en rnns (redes ne...\n",
            "Fragmento 71: continua de palabras (cbow), otro se llama skip-gr...\n",
            "Fragmento 72: https://arxiv.org/pdf/1301.3781.pdf\n",
            "skip-gram\n",
            "para...\n",
            "Fragmento 73: verde, a partir de la palabra central:\n",
            "en el enfoq...\n",
            "Fragmento 74: neuronal para predecir palabras de contexto a part...\n",
            "Fragmento 75: con 300 características. entonces, la capa oculta ...\n",
            "Fragmento 76: se puede descargar aquí\n",
            "si dos palabras diferentes...\n",
            "Fragmento 77: veamos un ejemplo con (\n",
            "gensim\n",
            ") de carga de model...\n",
            "Fragmento 78: preentrenado (asegúrate de tener el archivo en tu ...\n",
            "Fragmento 79: imprime las palabras más similares y sus similitud...\n",
            "Fragmento 80: conejo similitud 0.7018613815307617 palabra montés...\n",
            "Fragmento 81: negativecuando usamos el método most_similar: \n",
            "res...\n",
            "Fragmento 82: más similares.\n",
            "cbowcbow, que significa \"continuous...\n",
            "Fragmento 83: \"el\", \"gato\", \"al\", \"ratón\".\n",
            "en este otro ejemplo,...\n",
            "Fragmento 84: palabra objetivo basándose en las palabras de cont...\n",
            "Fragmento 85: dimensiones v*n)\n",
            "•w’nv es la matriz de pesos que m...\n",
            "Fragmento 86: veamos un ejemplo de como entrenar un modelo cbow ...\n",
            "Fragmento 87: palabras más similares al contexto suministrado si...\n",
            "Fragmento 88: contexto (context_words) es: most_probable_word\" e...\n",
            "Fragmento 89: excluir las palabras en context_words. luego, sele...\n",
            "Fragmento 90: palabra-palabra de un corpus, y las representacion...\n",
            "Fragmento 91: precisas extraídas de un corpus de 6 mil millones ...\n",
            "Fragmento 92: (también llamada \"palabra de prueba\"):\n",
            "•es muy sim...\n",
            "Fragmento 93: \"gas\", mientras que \"vapor\" co-ocurre más frecuent...\n",
            "Fragmento 94: hielo, y los valores pequeños (mucho menores que 1...\n",
            "Fragmento 95: lado, glove es un método de aprendizaje basado en ...\n",
            "Fragmento 96: •relaciones de palabras: ambos métodos son capaces...\n",
            "Fragmento 97: https://nlp.stanford.edu/projects/glove/\n",
            "https://t...\n",
            "Fragmento 98: una palabra específica word = \"king\" vector = embe...\n",
            "Fragmento 99: comparación con otras librerías) word = \"computer\"...\n",
            "Fragmento 100: ]\n",
            ".\n",
            ".\n",
            ".\n",
            "(\n",
            ".\n",
            "(\n",
            ")\n",
            ",\n",
            ".\n",
            "(\n",
            ")\n",
            ")\n",
            "(\n",
            "{\n",
            "}\n",
            "{\n",
            "}\n",
            "{\n",
            ".\n",
            "(\n",
            ")\n",
            "}\n",
            ")\n",
            "(\n",
            "...\n",
            "Fragmento 101: 1.bidireccionalidad: a diferencia de los modelos a...\n",
            "Fragmento 102: 3.pre-entrenamiento y afinación: bert se pre-entre...\n",
            "Fragmento 103: tradicionales como word2vec o glove, que generan u...\n",
            "Fragmento 104: y velocidad.\n",
            "6.multilingüe: además de los modelos ...\n",
            "Fragmento 105: bert genera embeddings y cómo lo hacen modelos com...\n",
            "Fragmento 106: modelos como word2vec y glove generan un único vec...\n",
            "Fragmento 107: de palabras enmascaradas y predicción de la siguie...\n",
            "Fragmento 108: embeddings de palabras o frases, su verdadero pode...\n",
            "Fragmento 109: recursos computacionales en comparación con word2v...\n",
            "Fragmento 110: •subpalabras y caracteres: en lugar de tokenizar s...\n",
            "Fragmento 111: original. en el ejemplo anterior, \"##iz\" y \"##able...\n",
            "Fragmento 112: veamos un ejemplo en python usando la librería :\n",
            "t...\n",
            "Fragmento 113: texto y obtener los ids de los tokens tokens = tok...\n",
            "Fragmento 114: word1_idxunsqueeze0 embeddings0word2_idxunsqueeze0...\n",
            "Fragmento 115: ,\n",
            "[\n",
            "]\n",
            "[\n",
            "]\n",
            ".\n",
            "(\n",
            ")\n",
            ")\n",
            "(\n",
            "{\n",
            "}\n",
            ")\n",
            "(\n",
            "{\n",
            ".\n",
            "(\n",
            ")\n",
            "}\n",
            ")\n",
            "fasttext\n",
            "e...\n",
            "Fragmento 116: https://arxiv.org/pdf/1607.04606v2.pdf\n",
            "1.subpalabr...\n",
            "Fragmento 117: para construir el vector de la palabra completa.\n",
            "2...\n",
            "Fragmento 118: términos de tiempo de entrenamiento y memoria, esp...\n",
            "Fragmento 119: idiomas, lo que facilita su uso en aplicaciones mu...\n",
            "Fragmento 120: !pip install fasttext !pip install huggingface_hub...\n",
            "Fragmento 121: import numpy as np # función para calcular la simi...\n",
            "Fragmento 122: similarity = cosine_similaritymodelget_word_vector...\n",
            "Fragmento 123: (\n",
            ".\n",
            "(\n",
            ")\n",
            ",\n",
            ".\n",
            "(\n",
            ")\n",
            ")\n",
            "(\n",
            "{\n",
            "}\n",
            ")\n",
            "(\n",
            ".\n",
            "(\n",
            ")\n",
            ",\n",
            ".\n",
            "(\n",
            ")\n",
            ")\n",
            "(\n",
            "{\n",
            "}\n",
            "...\n",
            "Fragmento 124: y 'casualidad': 0.08354239910840988\n",
            "fasttext mejor...\n",
            "Fragmento 125: palabra.\n",
            "aquí podemos ver como fasttext descompone...\n",
            "Fragmento 126: elmo (embeddings from language model)\n",
            "es un método...\n",
            "Fragmento 127: escriben igual pero tienen diferentes significados...\n",
            "Fragmento 128: 3.sensibilidad al contexto: a diferencia de los em...\n",
            "Fragmento 129: mediante una cnn. en cada paso de tiempo, la repre...\n",
            "Fragmento 130: normaliza durante el entrenamiento.\n",
            "veamos un ejem...\n",
            "Fragmento 131: overrides==3.1.0\n",
            ":\n",
            ".\n",
            ".\n",
            "cargamos el modelo desde la...\n",
            "Fragmento 132: contexto financiero 'me' 'senté' 'en' 'el' 'banco'...\n",
            "Fragmento 133: embeddings # el embedding de la palabra \"banco\" se...\n",
            "Fragmento 134: (\n",
            ")\n",
            ",\n",
            "(\n",
            ",\n",
            ")\n",
            "(\n",
            "(\n",
            ",\n",
            ")\n",
            ")\n",
            ":\n",
            ".\n",
            "(\n",
            ")\n",
            "[\n",
            "]\n",
            "[\n",
            "]\n",
            "(\n",
            "{\n",
            "}\n",
            "{\n",
            "}\n",
            ")\n",
            "...\n",
            "Fragmento 135: 0.46354493]\n",
            "más información:\n",
            "video de dotcsvlos in...\n",
            "Fragmento 136: principales:\n",
            "los métodos count vectorizer y tf-idf...\n",
            "Fragmento 137: hash vectorizeroración\n",
            "count vectorizeroración ✓\n",
            "t...\n",
            "Fragmento 138: ejemplo, 100, 200, 300 o más), se utilizan técnica...\n",
            "Fragmento 139: están agrupados en el espacio.\n",
            "t-sne (t-distribute...\n",
            "Fragmento 140: pca (principal component analysis)\n",
            "vemos un ejempl...\n",
            "Fragmento 141: keyedvectorsload_word2vec_format'sbw-vectors-300-m...\n",
            "Fragmento 142: pltscatterembeddings_2di 0 embeddings_2di 1 marker...\n",
            "Fragmento 143: para una lista de palabras y luego visualizará est...\n",
            "Fragmento 144: binary=true # lista de palabras para visualizar wo...\n",
            "Fragmento 145: df'word' = words # visualizar los embeddings en 3d...\n",
            "Fragmento 146: https://projector.tensorflow.org/\n",
            "https://towardsd...\n",
            "Fragmento 147: oraciones buscan capturar el significado semántico...\n",
            "Fragmento 148: nlp, como la clasificación de texto, la búsqueda p...\n",
            "Fragmento 149: ), \n",
            " (\n",
            "sentence-transformers\n",
            "), o  han sido\n",
            "entren...\n",
            "Fragmento 150: •representación unificada: proporcionan una repres...\n",
            "Fragmento 151: 6.uso en modelos de aprendizaje profundo: las incr...\n",
            "Fragmento 152: promediar vectores de palabras para incrustar\n",
            "orac...\n",
            "Fragmento 153: continuación utilizando vectores de palabras prome...\n",
            "Fragmento 154: obtenida a partir de vectores de palabras promedia...\n",
            "Fragmento 155: obtener incrustaciones de oraciones\n",
            "universal sent...\n",
            "Fragmento 156: dada en una representación de oración de 512 dimen...\n",
            "Fragmento 157: amplia variedad de tareas de nlp, como la relación...\n",
            "Fragmento 158: diferentes idiomas. \n",
            "veamos un ejemplo:# primero p...\n",
            "Fragmento 159: embeddings_2 labels_1 labels_2 plot_title plot_wid...\n",
            "Fragmento 160: embeddings_2_colappendlabels_2j sim_colappendsimij...\n",
            "Fragmento 161: ||| @embeddings_2' 'sim' '@sim' prectx=\"embeddings...\n",
            "Fragmento 162: 300 bokehiooutput_notebook bokehioshowp # el model...\n",
            "Fragmento 163: '我喜欢和我的狗一起沿着海滩散步。 ' english_sentences = 'dog' 'pup...\n",
            "Fragmento 164: cane.' japanese_sentences = '犬' '子犬はいいです ' '私は犬と 一...\n",
            "Fragmento 165: embed_textenglish_sentences es_result = embed_text...\n",
            "Fragmento 166: .\n",
            "(\n",
            ",\n",
            ",\n",
            ",\n",
            "[\n",
            "(\n",
            ")\n",
            "]\n",
            ",\n",
            ",\n",
            ",\n",
            ",\n",
            ",\n",
            "[\n",
            "(\n",
            ",\n",
            ")\n",
            ",\n",
            "(\n",
            ",\n",
            ")\n",
            "]\n",
            ")\n",
            ".\n",
            "...\n",
            "Fragmento 167: inglés'\n",
            "(\n",
            ")\n",
            "(\n",
            ")\n",
            "(\n",
            ")\n",
            "(\n",
            ",\n",
            ",\n",
            ",\n",
            ",\n",
            ")\n",
            "y obtendremos un g...\n",
            "\n",
            "Fragmentos de la Unidad 3:\n",
            "Fragmento 1: unidad 3 - procesamiento del\n",
            "lenguaje\n",
            "1. extracció...\n",
            "Fragmento 2: principal de una frase sustantiva es nombrar o ide...\n",
            "Fragmento 3: frase sustantiva.\n",
            "2.determinante: palabras como ar...\n",
            "Fragmento 4: •\"el\" es el determinante.\n",
            "•\"perro\" es el núcleo.\n",
            "•...\n",
            "Fragmento 5: modelos para idioma español\n",
            "pip install spacy pyth...\n",
            "Fragmento 6: .\n",
            "(\n",
            ")\n",
            "(\n",
            ")\n",
            ".\n",
            ":\n",
            "(\n",
            ".\n",
            ")\n",
            "y el resultado será:\n",
            "el veloz ...\n",
            "Fragmento 7: •\"el\" es el determinante.\n",
            "•\"perro\" es el núcleo o ...\n",
            "Fragmento 8: concepto es fundamental para varias aplicaciones d...\n",
            "Fragmento 9: vectorización de texto como tf-idf y embeddings de...\n",
            "Fragmento 10: número de elementos comunes dividido por el número...\n",
            "Fragmento 11: una pregunta dada en una base de datos de conocimi...\n",
            "Fragmento 12: lista de documentos (frases en español) documents ...\n",
            "Fragmento 13: similitud del coseno para la primera oración con e...\n",
            "Fragmento 14: despejado hoy.' es: 'me gusta salir a caminar bajo...\n",
            "Fragmento 15: distancia de coseno:\n",
            "es una transformación de la s...\n",
            "Fragmento 16: están dos vectores entre sí. \n",
            "distancia de jaccard...\n",
            "Fragmento 17: • ∣a∩b ∣ es el número de elementos en la intersecc...\n",
            "Fragmento 18: de documentos o textos. por ejemplo, para comparar...\n",
            "Fragmento 19: con la pelota\" frase_2 = \"el perro corre tras la p...\n",
            "Fragmento 20: (\n",
            ",\n",
            ")\n",
            ":\n",
            ".\n",
            "(\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            "(\n",
            ")\n",
            "(\n",
            ")\n",
            "(\n",
            ".\n",
            "(\n",
            ")\n",
            ")\n",
            "(\n",
            ".\n",
            "(\n",
            ")\n",
            ")\n",
            "(\n",
            "...\n",
            "Fragmento 21: sofá.\" \"los niños juegan en el parque con una pelo...\n",
            "Fragmento 22: similarity = jaccard_scorevector_1 vector_2 averag...\n",
            "Fragmento 23: \"los niños corren en el parque con un balón.\" is: ...\n",
            "Fragmento 24: métrica utilizada para calcular la similitud entre...\n",
            "Fragmento 25: comunes entre a y b).\n",
            "• ∣a ∣ y ∣b ∣ son el número ...\n",
            "Fragmento 26: (\n",
            ",\n",
            ")\n",
            ":\n",
            ".\n",
            "(\n",
            ")\n",
            "(\n",
            ")\n",
            "(\n",
            "(\n",
            ")\n",
            "(\n",
            ")\n",
            ")\n",
            "(\n",
            ".\n",
            "(\n",
            ")\n",
            ")\n",
            "(\n",
            ".\n",
            "(\n",
            ")\n",
            ")\n",
            "...\n",
            "Fragmento 27: generalmente dará un valor más alto que la similit...\n",
            "Fragmento 28: operaciones de edición permitidas son:\n",
            "1.inserción...\n",
            "Fragmento 29: .\n",
            "(\n",
            ",\n",
            ")\n",
            "(\n",
            "{\n",
            "}\n",
            ")\n",
            "coincidencia fonética (phonetic ma...\n",
            "Fragmento 30: palabras que tienen una pronunciación similar. est...\n",
            "Fragmento 31: soundex = soundex # palabras para comparar word1 =...\n",
            "Fragmento 32: (\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            ":\n",
            "(\n",
            "{\n",
            "}\n",
            "{\n",
            "}\n",
            ")\n",
            ":\n",
            "(\n",
            "{\n",
            "}\n",
            "{\n",
            "}\n",
            ")\n",
            "y el r...\n",
            "Fragmento 33: metaphone = metaphone()).\n",
            "también podemos calcular...\n",
            "Fragmento 34: (levenshtein) dist = rsdistance'mister' 'master' p...\n",
            "Fragmento 35: significa que las palabras sean idénticas, sino qu...\n",
            "Fragmento 36: refined soundex.\n",
            "en el caso de \"mister\" y \"master\"...\n",
            "Fragmento 37: medir la diferencia entre dos cadenas de igual lon...\n",
            "Fragmento 38: en un texto en categorías predefinidas como nombre...\n",
            "Fragmento 39: texto.\n",
            "2.clasificación de entidades: una vez ident...\n",
            "Fragmento 40: •búsqueda semántica: para mejorar los motores de b...\n",
            "Fragmento 41: ,\n",
            "donde podemos visualizar la precisión y el estad...\n",
            "Fragmento 42: guterres indicó que el clima está implosionando má...\n",
            "Fragmento 43: rápido de lo que podemos hacer frente, con fenómen...\n",
            "Fragmento 44: y grandes daños en las economías y el medioambient...\n",
            "Fragmento 45: locations, mountain ranges, bodies of water entida...\n",
            "Fragmento 46: bodies of water\n",
            "vemos como el modelo, detecta las ...\n",
            "Fragmento 47: etc org empresas agencias instituciones etc gpe pa...\n",
            "Fragmento 48: porcentaje incluyendo ”%“ money valores monetarios...\n",
            "Fragmento 49: los resultados de forma más atractiva en colab:\n",
            "#v...\n",
            "Fragmento 50: categorizar entidades específicas dentro de un tex...\n",
            "Fragmento 51: modo de evaluación, esto es útil para desactivar c...\n",
            "Fragmento 52: no hay vuelta a la normalidad. la tecnología está ...\n",
            "Fragmento 53: ser, no solo en américa, sino globalmente\", le dij...\n",
            "Fragmento 54: y nick krishnamurthy. descubre más a continuación,...\n",
            "Fragmento 55: printentity\"text\" \"=>\" entity\"label\"\n",
            ".\n",
            "(\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            "[...\n",
            "Fragmento 56: crucial del procesamiento del lenguaje natural que...\n",
            "Fragmento 57: número, tiempo, etc.\n",
            "2.dependencia del contexto: l...\n",
            "Fragmento 58: tener más de una categoría gramatical.\n",
            "6.reglas gr...\n",
            "Fragmento 59: un paso previo al ner, ayudando a identificar sust...\n",
            "Fragmento 60: traducirlas correctamente.\n",
            "5.respuesta a preguntas...\n",
            "Fragmento 61: análisis de sentimientos.\n",
            "veamos un ejemplo con sp...\n",
            "Fragmento 62: nlptexto # crear una lista para almacenar las pala...\n",
            "Fragmento 63: )\n",
            "(\n",
            ")\n",
            "y obtendremos una tabla como la siguiente:\n",
            "p...\n",
            "Fragmento 64: determiner 17 hueso noun noun 18 . punct punctuati...\n",
            "Fragmento 65: .\n",
            "(\n",
            ",\n",
            ",\n",
            ")\n",
            ".\n",
            "(\n",
            ",\n",
            ")\n",
            "(\n",
            ")\n",
            ".\n",
            "(\n",
            ",\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            "juan \n",
            "propny \n",
            "...\n",
            "Fragmento 66: texto.\n",
            "otra librería que podemos usar para realiza...\n",
            "Fragmento 67: intj interjección ¡eh!, ¡ay!, ¡bravo!, ¡hola!\n",
            "noun...\n",
            "Fragmento 68: comió, comiendo\n",
            "x otro sfpksdpsxmsa\n",
            "space espacio#...\n",
            "Fragmento 69: texas, ya realiza sus primeras tareas en una empre...\n",
            "Fragmento 70: case aspecto aspecto noun 2 nmod humanoide humanoi...\n",
            "Fragmento 71: obj tediosas tedioso adj 21 amod y y cconj 24 cc a...\n",
            "Fragmento 72: realiza realizar verb 0 root sus su det 21 det pri...\n",
            "Fragmento 73: •word.pos: la etiqueta de parte del habla (part of...\n",
            "Fragmento 74: (deprel):\n",
            "universal dependencies•nsubj: (nominal s...\n",
            "Fragmento 75: •nmod: (nominal modifier) un modificador nominal d...\n",
            "Fragmento 76: •cc: (coordinating conjunction) una conjunción coo...\n",
            "Fragmento 77: •obl: (oblique) un argumento no sujeto ni objeto d...\n",
            "Fragmento 78: evitar\", \"para\" es un marcador.\n",
            "•case: (case marki...\n",
            "Fragmento 79: \"la empresa\", \"la\" es el determinante de \"empresa\"...\n",
            "Fragmento 80: que involucra la asignación de una o más categoría...\n",
            "Fragmento 81: pasos:\n",
            "1.recolección de datos: obtención de un con...\n",
            "Fragmento 82: 4.entrenamiento del modelo: utilizar un algoritmo ...\n",
            "Fragmento 83: ejemplo con tf-idf y regresión logística\n",
            "en el eje...\n",
            "Fragmento 84: el vectorizador también elimina las palabras vacía...\n",
            "Fragmento 85: regresión logísticafrom sklearnmodel_selection imp...\n",
            "Fragmento 86: de software\" 1 \"videojuegos\" 2 \"inteligencia artif...\n",
            "Fragmento 87: para el desarrollo web.\" datasetappend0 \"html y cs...\n",
            "Fragmento 88: necesario para asegurar la calidad del software.\" ...\n",
            "Fragmento 89: ganado mucha popularidad.\" datasetappend1 \"las con...\n",
            "Fragmento 90: requiere un buen joystick.\" # textos de \"inteligen...\n",
            "Fragmento 91: datasetappend2 \"las redes neuronales profundas son...\n",
            "Fragmento 92: red neuronal.\" datasetappend2 \"las redes neuronale...\n",
            "Fragmento 93: (\n",
            ",\n",
            ")\n",
            ")\n",
            ".\n",
            "(\n",
            "(\n",
            ",\n",
            ")\n",
            ")\n",
            ".\n",
            "(\n",
            "(\n",
            ",\n",
            ")\n",
            ")\n",
            ".\n",
            "(\n",
            "(\n",
            ",\n",
            ")\n",
            ")\n",
            ".\n",
            "(\n",
            "(\n",
            "...\n",
            "Fragmento 94: firewalls ayudan a proteger las redes corporativas...\n",
            "Fragmento 95: datasetappend3 \"el spyware es un tipo de malware.\"...\n",
            "Fragmento 96: test_size=0.2 random_state=42 # vectorización de l...\n",
            "Fragmento 97: del modelo de regresión logística y_pred_lr =\n",
            "mode...\n",
            "Fragmento 98: )\n",
            ".\n",
            "(\n",
            "(\n",
            ",\n",
            ")\n",
            ")\n",
            "[\n",
            ".\n",
            "(\n",
            ")\n",
            ",\n",
            "]\n",
            "[\n",
            ",\n",
            "]\n",
            ",\n",
            ",\n",
            ",\n",
            "(\n",
            ",\n",
            ",\n",
            ",\n",
            ")\n",
            "(\n",
            "...\n",
            "Fragmento 99: 11\n",
            "una vez que tenemos nuestro modelo entrenado, p...\n",
            "Fragmento 100: nuevas_frases = fraselower for frase in nuevas_fra...\n",
            "Fragmento 101: frase 'nuevas_frasesi' pertenece a la categoría: l...\n",
            "Fragmento 102: vectorizerget_feature_names_out coef = modelo_lrco...\n",
            "Fragmento 103: .\n",
            "(\n",
            "[\n",
            "]\n",
            ")\n",
            "[\n",
            ":\n",
            "]\n",
            "[\n",
            "[\n",
            "]\n",
            "]\n",
            "[\n",
            "]\n",
            "[\n",
            "]\n",
            ".\n",
            "(\n",
            ")\n",
            ".\n",
            "(\n",
            ",\n",
            ")\n",
            ".\n",
            "(\n",
            "...\n",
            "Fragmento 104: podemos utilizar modelos de embeddings para conver...\n",
            "Fragmento 105: sklearnmodel_selection import train_test_split fro...\n",
            "Fragmento 106: 0 \"desarrollo de software\" 1 \"videojuegos\" 2 \"inte...\n",
            "Fragmento 107: \"javascript es esencial para el desarrollo web.\" d...\n",
            "Fragmento 108: datasetappend0 \"el testing es necesario para asegu...\n",
            "Fragmento 109: requieren una buena tarjeta gráfica.\" datasetappen...\n",
            "Fragmento 110: industrias.\" datasetappend2 \"la robótica es una ap...\n",
            "Fragmento 111: es una técnica de aprendizaje automático.\" dataset...\n",
            "Fragmento 112: buenas para el reconocimiento de imágenes.\" # text...\n",
            "Fragmento 113: )\n",
            ".\n",
            "(\n",
            "(\n",
            ",\n",
            ")\n",
            ")\n",
            ".\n",
            "(\n",
            "(\n",
            ",\n",
            ")\n",
            ")\n",
            ".\n",
            "(\n",
            "(\n",
            ",\n",
            ")\n",
            ")\n",
            ".\n",
            "(\n",
            "(\n",
            ",\n",
            ")\n",
            ")\n",
            "...\n",
            "Fragmento 114: ciberseguridad.\" datasetappend3 \"la ingeniería soc...\n",
            "Fragmento 115: demandada.\" datasetappend3 \"los hackers éticos ayu...\n",
            "Fragmento 116: y entrenamiento del modelo de regresión logística ...\n",
            "Fragmento 117: nuevas frases para clasificar new_phrases =  \"quis...\n",
            "Fragmento 118: mostrando las predicciones junto con las frases fo...\n",
            "Fragmento 119: )\n",
            "]\n",
            ".\n",
            "(\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            ",\n",
            "(\n",
            ",\n",
            ")\n",
            ":\n",
            "(\n",
            "{\n",
            "}\n",
            ")\n",
            "(\n",
            "{\n",
            "[\n",
            "]\n",
            "[\n",
            "]\n",
            "}\n",
            ")\n",
            "...\n",
            "Fragmento 120: videojuegos de realidad virtual son increíbles.' c...\n",
            "Fragmento 121: opiniones o emociones expresadas en un texto. esen...\n",
            "Fragmento 122: hacia el tema.\n",
            "2.intensidad:\n",
            "•la fuerza del sentim...\n",
            "Fragmento 123: de sentimiento asignada.\n",
            "2.machine learning:\n",
            "•util...\n",
            "Fragmento 124: aplicaciones:\n",
            "•análisis de productos: para entende...\n",
            "Fragmento 125: requiere un entendimiento profundo del lenguaje.\n",
            "•...\n",
            "Fragmento 126: posteriormente, el modelo utiliza un clasificador ...\n",
            "Fragmento 127: sentiment_analysissentimentanalysisspanish\n",
            "printse...\n",
            "Fragmento 128: recopiladas a través de web scraping.\n",
            "veamos otro ...\n",
            "Fragmento 129: berttokenizerfrom_pretrainedmodel_name model =\n",
            "ber...\n",
            "Fragmento 130: predicciones de sentimiento para cada frase for fr...\n",
            "Fragmento 131: back again.' sentimiento: 5 stars, score: 0.525 fr...\n",
            "Fragmento 132: cercanos entre la consulta y los documentos del co...\n",
            "Fragmento 133: longitudes similares, lo que facilita la comparaci...\n",
            "Fragmento 134: como una pregunta o algunas palabras clave, y se b...\n",
            "Fragmento 135: contenido.\n",
            "ejemplo\n",
            "si tu consulta es \"¿qué es pyth...\n",
            "Fragmento 136: proporcionados pueden ser utilizados para búsqueda...\n",
            "Fragmento 137: :\n",
            "modelo específico de preguntas y respuestas\n",
            "basa...\n",
            "Fragmento 138: tiranosaurios?\" \"¿cómo se extinguieron los dinosau...\n",
            "Fragmento 139: temible de la historia.' 'el tiranosaurio rex vivi...\n",
            "Fragmento 140: plantas, algas y algunas bacterias convierten la l...\n",
            "Fragmento 141: = utilcos_simincrustacion_consulta incrustaciones_...\n",
            "Fragmento 142: 0.4851): londres tenía 9,787,426 habitantes según ...\n",
            "Fragmento 143: en el planeta? mejor respuesta (similitud: 0.6135)...\n",
            "Fragmento 144: respuesta (similitud: 0.5550): el tiranosaurio rex...\n",
            "Fragmento 145: respuesta. ejemplo:\n",
            "util.semantic_search\n",
            "# encontr...\n",
            "Fragmento 146: ]\n",
            "}\n",
            ")\n",
            ",\n",
            "(\n",
            "[\n",
            "]\n",
            ")\n",
            ":\n",
            "(\n",
            "{\n",
            "}\n",
            "{\n",
            "[\n",
            "]\n",
            ":\n",
            "}\n",
            "{\n",
            "[\n",
            "[\n",
            "]\n",
            "]\n",
            "}\n",
            ")\n",
            "(\n",
            "...\n",
            "Fragmento 147: respuesta 3 (similitud: 0.4039): el alimento prefe...\n",
            "Fragmento 148: herramientas como annoy (\n",
            "annoy\n",
            ") y faiss (\n",
            "faiss\n",
            "...\n",
            "Fragmento 149: es un paso crucial en muchas aplicaciones de nlp, ...\n",
            "Fragmento 150: 2.modelos estadísticos:\n",
            "•otros métodos utilizan mo...\n",
            "Fragmento 151: gramas de caracteres y un modelo de tipo naive bay...\n",
            "Fragmento 152: la musique.\" idioma = detecttexto printidioma #imp...\n",
            "Fragmento 153: de idiomas posibles.\n",
            "•para mejorar la precisión, e...\n",
            "Fragmento 154: (\n",
            ")\n",
            "(\n",
            ")\n",
            "otra opción es usar fasttext-langdetect(\n",
            "f...\n",
            "Fragmento 155: palabras y documentos como vectores. para la detec...\n",
            "Fragmento 156: un texto para detectar su idioma, fasttext-langdet...\n",
            "Fragmento 157: low_memory=true printresult # imprime: # {'lang': ...\n",
            "Fragmento 158: langid.py\n",
            " o \n",
            "cld2\n",
            " (c++). también existen muchas ...\n",
            "Fragmento 159: \"traducción automática\". el concepto de automatiza...\n",
            "Fragmento 160: metodologías que han mejorado la calidad de la tra...\n",
            "Fragmento 161: siguiente figura:aquí mencionamos las cuatro ramas...\n",
            "Fragmento 162: semánticas, morfológicas y sintácticas de cada idi...\n",
            "Fragmento 163: automática a menudo caracterizado por su uso de un...\n",
            "Fragmento 164: de que la traducción se realiza por analogía es un...\n",
            "Fragmento 165: analogía está codificado en la traducción automáti...\n",
            "Fragmento 166: generalizaba a otros idiomas. desde 2003, el enfoq...\n",
            "Fragmento 167: traducción automática\n",
            "r\n",
            "aprendizaje profundo\n",
            "aquí ...\n",
            "Fragmento 168: traducción inputs = tokenizertexto_español return_...\n",
            "Fragmento 169: la traducción inversa, de inglés a español.\n",
            "librer...\n",
            "Fragmento 170: para ser utilizado desde la librería:\n",
            "from deep_tr...\n",
            "Fragmento 171: ponstranslatorsource='english' target='spanish'tra...\n",
            "Fragmento 172: que proporciona acceso a grandes cantidades de par...\n",
            "Fragmento 173: unión europea, las naciones unidas y alineando los...\n",
            "Fragmento 174: printtstranslate_textq_text translator='google' to...\n",
            "Fragmento 175: síntesis de voz\n",
            "el tts (text-to_speech) y el asr (...\n",
            "Fragmento 176: lenguaje.2.generación de sonido:\n",
            "•los fonemas se c...\n",
            "Fragmento 177: hace varias décadas:\n",
            "https://link.springer.com/art...\n",
            "Fragmento 178: sonar menos natural.\n",
            "3.síntesis de voz basada en a...\n",
            "Fragmento 179: servicio de síntesis de voz proporcionado por goog...\n",
            "Fragmento 180: de audio ttssave\"saludo.mp3\" # reproducir el archi...\n",
            "Fragmento 181: 12. modelado de tópicos (topic modeling)\n",
            "el modela...\n",
            "Fragmento 182: topic modeling\n",
            "el modelado de tópicos ayuda a desc...\n",
            "Fragmento 183: algunas técnicas comunes de modelado de tópicos in...\n",
            "Fragmento 184: top2vec ( )\n",
            "https://arxiv.org/pdf/2008.09470.pdfto...\n",
            "Fragmento 185: palabras para hallar vectores de tópicos. los vect...\n",
            "\n",
            "Fragmentos de la Unidad 4:\n",
            "Fragmento 1: unidad 4 - arquitecturas de\n",
            "modelos de lenguaje\n",
            "in...\n",
            "Fragmento 2: complejidad y eficacia para abordar las tareas de ...\n",
            "Fragmento 3: procesan secuencias de texto. sin embargo, las rnn...\n",
            "Fragmento 4: secuencia. la evolución natural llevó al surgimien...\n",
            "Fragmento 5: estándares de estado del arte, impulsando una seri...\n",
            "Fragmento 6: rápido cambio de la inteligencia artificial.\n",
            "1. rn...\n",
            "Fragmento 7: la siguiente entrada a2 (palabra “buenos”), la red...\n",
            "Fragmento 8: rnns son un modelo adecuado para tratar con secuen...\n",
            "Fragmento 9: secuencia de datos importa.\n",
            "•entrada de longitud v...\n",
            "Fragmento 10: los precios de las acciones o las lecturas del cli...\n",
            "Fragmento 11: •reconocimiento de voz: cuando hablamos, los sonid...\n",
            "Fragmento 12: memoria es lo que hace especiales a las rnns. \n",
            "en ...\n",
            "Fragmento 13: representación simplificada de una rnn\n",
            "en una celd...\n",
            "Fragmento 14: entender la diferencia:\n",
            "•red neuronal feedforward:...\n",
            "Fragmento 15: contexto de las redes neuronales recurrentes (rnns...\n",
            "Fragmento 16: específico).\n",
            "2.luego, xt-1, la versión codificada ...\n",
            "Fragmento 17: vector cero.\n",
            "3.producir la palabra real (”voluntee...\n",
            "Fragmento 18: podemos ver cómo cada uno de {…, h t-1, h t, h t+1...\n",
            "Fragmento 19: el \"padding\" es una técnica utilizada en el proces...\n",
            "Fragmento 20: entrena el modelo:\n",
            "import tensorflow as tf from te...\n",
            "Fragmento 21: tokenizertexts_to_sequencesdata print'\\nsequences:...\n",
            "Fragmento 22: sequential embeddinginput_dim=vocab_size output_di...\n",
            "Fragmento 23: ]\n",
            "[\n",
            ":\n",
            ",\n",
            "]\n",
            "(\n",
            "{\n",
            "}\n",
            "{\n",
            "}\n",
            ")\n",
            "(\n",
            "[\n",
            "(\n",
            ",\n",
            ",\n",
            ")\n",
            ",\n",
            "(\n",
            ")\n",
            ",\n",
            "(\n",
            ",\n",
            ")\n",
            "]\n",
            "...\n",
            "Fragmento 24: 32 1376 dense_1 dense none 11 363\n",
            "================...\n",
            "Fragmento 25: [\n",
            "[\n",
            ",\n",
            ",\n",
            "]\n",
            ",\n",
            "[\n",
            ",\n",
            ",\n",
            "]\n",
            ",\n",
            "[\n",
            ",\n",
            ",\n",
            "]\n",
            ",\n",
            "[\n",
            ",\n",
            "]\n",
            "]\n",
            ":\n",
            "[\n",
            "[\n",
            "]\n",
            "[\n",
            "...\n",
            "Fragmento 26: , y dense. a continuación, veamos qué hacen cada u...\n",
            "Fragmento 27: un token especial de padding).\n",
            "•el segundo argumen...\n",
            "Fragmento 28: simple.\n",
            "simplernn\n",
            "•el argumento 32 se refiere a la...\n",
            "Fragmento 29: •vocab_size es el número de unidades en la capa, q...\n",
            "Fragmento 30: siguiente palabra en la secuencia.\n",
            "•activation='so...\n",
            "Fragmento 31: simplernn, y finalmente utiliza una capa dense par...\n",
            "Fragmento 32: = tokenizertexts_to_sequencestext0 # aplicar paddi...\n",
            "Fragmento 33: printf\"la siguiente palabra predicha después de 't...\n",
            "Fragmento 34: dimensión de 10 a 50 o 100.\n",
            "•añadir múltiples capa...\n",
            "Fragmento 35: datos generalmente conducen a mejores resultados, ...\n",
            "Fragmento 36: procesamiento de secuencias, pero presentan varios...\n",
            "Fragmento 37: sean ineficientes para capturar relaciones en secu...\n",
            "Fragmento 38: mientras que la explosión del gradiente puede hace...\n",
            "Fragmento 39: sobreajustarse, especialmente cuando se tiene un n...\n",
            "Fragmento 40: decisiones específicas.\n",
            "tipos de redes rnn\n",
            "las rnn...\n",
            "Fragmento 41: 2.sequence to vector (secuencia a vector)\n",
            "•descrip...\n",
            "Fragmento 42: vectorial de una imagen, produce una secuencia de ...\n",
            "Fragmento 43: ese vector para generar una secuencia más corta qu...\n",
            "Fragmento 44: https://www.youtube.com/watch?v=hb4xyst_t-i\n",
            "2. lst...\n",
            "Fragmento 45: características clave de las lstm:\n",
            "1.memoria a lar...\n",
            "Fragmento 46: debe mantener o descartar en cada paso de tiempo. ...\n",
            "Fragmento 47: 3.celda de memoria: es el componente central de la...\n",
            "Fragmento 48: tradicionales. sin embargo, aunque las lstm son me...\n",
            "Fragmento 49: la celda se vale de los siguientes elementos, para...\n",
            "Fragmento 50: decisión, produciendo valores entre 0 (olvidar) y ...\n",
            "Fragmento 51: toma la entrada actual y el estado oculto anterior...\n",
            "Fragmento 52: cercanos a 0 o 1, tomando decisiones prácticamente...\n",
            "Fragmento 53: como está (de principio a fin), mientras que la ot...\n",
            "Fragmento 54: adicional de procesamiento, las lstms bidirecciona...\n",
            "Fragmento 55: tensorflowkeraslayers import lstm dense embedding ...\n",
            "Fragmento 56: 1/master/cien.txt\" corpus = openpathreadlower # el...\n",
            "Fragmento 57: tokenizer_file # crear secuencias de entrada input...\n",
            "Fragmento 58: intleninput_sequences * fraction input_sequences =...\n",
            "Fragmento 59: modeladdlstm150 modeladddense512 activation='relu'...\n",
            "Fragmento 60: para generar texto después de cada época class gen...\n",
            "Fragmento 61: predicted = npargmaxselfmodelpredicttoken_list axi...\n",
            "Fragmento 62: .\n",
            "(\n",
            "(\n",
            ",\n",
            ")\n",
            ")\n",
            ".\n",
            "(\n",
            "(\n",
            ",\n",
            ")\n",
            ")\n",
            "(\n",
            ")\n",
            ".\n",
            "(\n",
            ",\n",
            ",\n",
            "[\n",
            "]\n",
            ")\n",
            ":\n",
            ".\n",
            ".\n",
            "(\n",
            "...\n",
            "Fragmento 63: {\n",
            "}\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            ".\n",
            "(\n",
            ",\n",
            ",\n",
            ",\n",
            ",\n",
            "[\n",
            "(\n",
            ")\n",
            "]\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            "nues...\n",
            "Fragmento 64: 8095140\n",
            "==========================================...\n",
            "Fragmento 65: es decir, realizamos la predicción de una palabra,...\n",
            "Fragmento 66: pad_sequences # cargar el tokenizador (asumiendo q...\n",
            "Fragmento 67: next_words max_sequence_len tokenizer model for _ ...\n",
            "Fragmento 68: printgenerated_text\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            "(\n",
            ",\n",
            ")\n",
            ":\n",
            ".\n",
            "(\n",
            ")\n",
            "(\n",
            ".\n",
            ")\n",
            "...\n",
            "Fragmento 69: 2. :\n",
            "regularización\n",
            "•dropout: añadir capas de drop...\n",
            "Fragmento 70: 4.ajuste de hiperparámetros:\n",
            "•tasa de aprendizaje:...\n",
            "Fragmento 71: cero, se pueden utilizar embeddings preentrenados ...\n",
            "Fragmento 72: imágenes, podemos crear versiones \"alteradas\" de l...\n",
            "Fragmento 73: sobreajuste.\n",
            "las lstm como clasificadores\n",
            "las lstm...\n",
            "Fragmento 74: película. cada palabra de la reseña se convierte e...\n",
            "Fragmento 75: la generación de texto), solo nos interesa la últi...\n",
            "Fragmento 76: 2.la lstm procesa la secuencia palabra por palabra...\n",
            "Fragmento 77: ventajas de usar lstm para clasificación:\n",
            "•captura...\n",
            "Fragmento 78: lstms consideran el orden de las palabras, lo que ...\n",
            "Fragmento 79: más comunes top max_features) batch_size = 32 prin...\n",
            "Fragmento 80: print\"construyendo modelo...\" model = sequential\n",
            "m...\n",
            "Fragmento 81: score acc = modelevaluatex_test y_test batch_size=...\n",
            "Fragmento 82: de datos de imdb que utilizamos, # necesitaremos r...\n",
            "Fragmento 83: encode_texttext words = textsplit ids = word_to_id...\n",
            "Fragmento 84: printpredict_sentimenttext text = \"i did not enjoy...\n",
            "Fragmento 85: negativo (confianza: 0.99)\n",
            "más información:\n",
            "https:...\n",
            "Fragmento 86: las gru ofrecen una estructura más simplificada co...\n",
            "Fragmento 87: y qué información nueva se va a incorporar. esto a...\n",
            "Fragmento 88: reinicio, las gru calculan un nuevo estado oculto ...\n",
            "Fragmento 89: en los datos secuenciales.\n",
            "más información:\n",
            "https:...\n",
            "Fragmento 90: variantes avanzadas como las redes neuronales recu...\n",
            "Fragmento 91: de salida de longitud variable.\n",
            "en este contexto, ...\n",
            "Fragmento 92: como la salida son secuencias, y donde la longitud...\n",
            "Fragmento 93: secuencial.además, mientras que las arquitecturas ...\n",
            "Fragmento 94: la arquitectura de este modelo, surge del paper \n",
            ")...\n",
            "Fragmento 95: la siguiente figura:\n",
            "el modelo consta de 3 partes:...\n",
            "Fragmento 96: de todas las palabras de la pregunta. cada palabra...\n",
            "Fragmento 97: modelo. se calcula utilizando la fórmula anterior....\n",
            "Fragmento 98: unidad anterior y produce una salida así como su p...\n",
            "Fragmento 99: calculamos las salidas utilizando el estado oculto...\n",
            "Fragmento 100: correlacionadas y sus longitudes pueden diferir. e...\n",
            "Fragmento 101: no es capaz de capturar toda la información.\n",
            "los m...\n",
            "Fragmento 102: 5.reconocimiento de voz: transcribir audio a texto...\n",
            "Fragmento 103: paper \"attention is all you need\"\n",
            "neural machine\n",
            "t...\n",
            "Fragmento 104: embeddings.\n",
            "conceptualización del flujo de informa...\n",
            "Fragmento 105: vectores largos y complejos con contenido abstract...\n",
            "Fragmento 106: diseñado para aliviar el problema de tener que enc...\n",
            "Fragmento 107: es exactamente idéntica a la palabra “yo”. “suis” ...\n",
            "Fragmento 108: ¿cómo funciona la atención?\n",
            "en la práctica, el mec...\n",
            "Fragmento 109: neural machine translation de jointly learning to ...\n",
            "Fragmento 110: entrada para la salida actual. esta función se eje...\n",
            "Fragmento 111: modificado de la traducción automática neuronal me...\n",
            "Fragmento 112: proporcionar al decodificador.\n",
            "neural machine tran...\n",
            "Fragmento 113: automática neuronal mediante el aprendizaje conjun...\n",
            "Fragmento 114: entrada en un vector de contexto, y un decodificad...\n",
            "Fragmento 115: largas, es posible que un simple vector de context...\n",
            "Fragmento 116: entrada influyen en la producción de tokens especí...\n",
            "Fragmento 117: mechanics-of-seq2seq-models-with-attention/\n",
            "https:...\n",
            "Fragmento 118: basaban en redes neuronales recurrentes o convoluc...\n",
            "Fragmento 119: subestimada; ha redefinido las mejores prácticas e...\n",
            "Fragmento 120: el ejemplo más común de una secuencia en este cont...\n",
            "Fragmento 121: información para realizar diversas tareas, incluye...\n",
            "Fragmento 122: altamente eficientes; capaces de procesar secuenci...\n",
            "Fragmento 123: tokens pueden ser tan pequeños como caracteres o t...\n",
            "Fragmento 124: un corpus de texto, permitiendo manejar palabras r...\n",
            "Fragmento 125: = bertmodelfrom_pretrained\"bert-base-multilingual-...\n",
            "Fragmento 126: ,\n",
            ".\n",
            "(\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            "(\n",
            ",\n",
            ")\n",
            "(\n",
            ")\n",
            "[\n",
            "]\n",
            "[\n",
            "]\n",
            "(\n",
            ")\n",
            "(\n",
            "[\n",
            "(\n",
            ")\n",
            "]\n",
            ")\n",
            ".\n",
            "...\n",
            "Fragmento 127: información que puede ser fácilmente procesada por...\n",
            "Fragmento 128: muy útil para preservar el orden de nuestros token...\n",
            "Fragmento 129: tokens aparecen.\n",
            "positional encoding\n",
            "para implemen...\n",
            "Fragmento 130: tienen longitudes diferentes, el modelo puede infe...\n",
            "Fragmento 131: cargar el modelo de spacy nlp = spacyload\"es_core_...\n",
            "Fragmento 132: position_enc 12 = cosines return position_encsquee...\n",
            "Fragmento 133: visualización pltfigurefigsize=12 6\n",
            "pltpcolormeshe...\n",
            "Fragmento 134: word_embedding = get_word_embeddingword pos_enc =\n",
            "...\n",
            "Fragmento 135: embedding codificado es position.\" # imprime: # la...\n",
            "Fragmento 136: )\n",
            "(\n",
            ",\n",
            ")\n",
            ".\n",
            "(\n",
            ".\n",
            "(\n",
            ")\n",
            ")\n",
            ":\n",
            "(\n",
            ")\n",
            "(\n",
            ",\n",
            ")\n",
            "(\n",
            ",\n",
            ")\n",
            "(\n",
            "{\n",
            "}\n",
            "{\n",
            "}\n",
            ")\n",
            "...\n",
            "Fragmento 137: importantes para comprender el token actual en el ...\n",
            "Fragmento 138: sobre sus tokens vecinos; en lugar de usar la mism...\n",
            "Fragmento 139: palabra.\n",
            "por ejemplo, \"pelota\" está estrechamente ...\n",
            "Fragmento 140: •the cat drank the milk because it was sweet.\n",
            "en l...\n",
            "Fragmento 141: palabra. esto se logra gracias a \"múltiples cabeza...\n",
            "Fragmento 142: por ejemplo, al traducirla a otro idioma, incorpor...\n",
            "Fragmento 143: para un problema de traducción)\n",
            "•la secuencia de d...\n",
            "Fragmento 144: codificada de la secuencia de entrada.\n",
            "3.la secuen...\n",
            "Fragmento 145: salida final.\n",
            "6.la función de pérdida del transfor...\n",
            "Fragmento 146: entrada.por lo tanto, al igual que en un modelo se...\n",
            "Fragmento 147: 1.la secuencia de entrada se convierte en embeddin...\n",
            "Fragmento 148: del conjunto de encoders para producir una represe...\n",
            "Fragmento 149: oración y la primera palabra.7.vuelve al paso #3. ...\n",
            "\n",
            "Fragmentos de la Unidad 5:\n",
            "Fragmento 1: unidad 5 - almacenamiento y\n",
            "representación del\n",
            "con...\n",
            "Fragmento 2: como aparecen en el espacio de datos buscable (sea...\n",
            "Fragmento 3: del usuario y el contexto semántico de la consulta...\n",
            "Fragmento 4: el más relevante según el contexto de la consulta....\n",
            "Fragmento 5: representaciones estructuradas de información y re...\n",
            "Fragmento 6: búsqueda.\n",
            "5.tecnologías de procesamiento del lengu...\n",
            "Fragmento 7: las relaciones entre diferentes conceptos y propor...\n",
            "Fragmento 8: bm25\n",
            "en forma general, estos métodos tokenizan o d...\n",
            "Fragmento 9: índice bm25 sobre una lista de elementos de texto ...\n",
            "Fragmento 10: moviliza embarcaciones de invasión a lo largo de l...\n",
            "Fragmento 11: casos\" \"tensiones crecientes\" # obtener el índice ...\n",
            "Fragmento 12: ----- ganador de lotería hombre de maine gana $1m ...\n",
            "Fragmento 13: crecientes tensiones con taiwán\n",
            "observemos que cad...\n",
            "Fragmento 14: resultado de coincidencia.\n",
            "¿pero qué pasa si quere...\n",
            "Fragmento 15: invasión a lo largo de la costa debido a las creci...\n",
            "Fragmento 16: climático\" \"salud pública\" \"guerra\" \"vida silvestr...\n",
            "Fragmento 17: ]\n",
            "(\n",
            "(\n",
            ",\n",
            ")\n",
            ")\n",
            "y en este caso los resultados serán:\n",
            "c...\n",
            "Fragmento 18: los textos de búsqueda no se encuentran en ninguna...\n",
            "Fragmento 19: vectorizar el contenido de entrada. la vectorizaci...\n",
            "Fragmento 20: luego).\n",
            "annuna vez creados los índices de vectores...\n",
            "Fragmento 21: sentence_transformers import sentencetransformer u...\n",
            "Fragmento 22: ganancias sin trabajar, gana hasta $100,000 al día...\n",
            "Fragmento 23: for consulta in \"de no creer\" \"cambio climático\" \"...\n",
            "Fragmento 24: ----- de no creer hombre de maine gana $1m con un ...\n",
            "Fragmento 25: engañosas obtén enormes ganancias sin trabajar, ga...\n",
            "Fragmento 26: de que las muestras similares tienden a estar cerc...\n",
            "Fragmento 27: y se guardan.\n",
            "•se ordenan las distancias calculada...\n",
            "Fragmento 28: algoritmo k-nearest neighbors (k-nn) de la bibliot...\n",
            "Fragmento 29: sentence-encoder-multilingual/3\" # lista de oracio...\n",
            "Fragmento 30: algorithm='brute' knnfitsentence_embeddings # cons...\n",
            "Fragmento 31: queriesi\" for j in rangen_neighbors printf\"vecino ...\n",
            "Fragmento 32: lenguaje natural vecino 1: el procesamiento de len...\n",
            "Fragmento 33: •n_neighbors=2: busca los 2 vecinos más cercanos.\n",
            "...\n",
            "Fragmento 34: la similitud coseno mide el coseno del ángulo entr...\n",
            "Fragmento 35: entonces, cuando imprimimos la distancia usando me...\n",
            "Fragmento 36: pero no necesariamente son los más cercanos absolu...\n",
            "Fragmento 37: puede ser muy costoso en tiempo y recursos. por lo...\n",
            "Fragmento 38: otro uso común es en la visión por computadora, do...\n",
            "Fragmento 39: la gran mejora en la velocidad.\n",
            "hay una serie de t...\n",
            "Fragmento 40: dividir los datos en una jerarquía de divisiones. ...\n",
            "Fragmento 41: • : este enfoque más reciente crea\n",
            "enlaces entre p...\n",
            "Fragmento 42: annoy (approximate nearest neighbors oh yeah) []\n",
            "a...\n",
            "Fragmento 43: solo árbol. durante la construcción del árbol, ann...\n",
            "Fragmento 44: más cercanos, divide el conjunto de puntos a la mi...\n",
            "Fragmento 45: search-in-high-dimensional-spaces.html\n",
            "un algoritm...\n",
            "Fragmento 46: exacto. esto es particularmente cierto cuando la m...\n",
            "Fragmento 47: o clase a un punto en función de sus vecinos. conc...\n",
            "Fragmento 48: sentence encoder embed = hubload\"https://tfhub.dev...\n",
            "Fragmento 49: sentence_embeddingsshape1 # asegurarse de que la d...\n",
            "Fragmento 50: for idx in nns printsentencesidx # imprime: # hola...\n",
            "Fragmento 51: de consumir más memoria. aumentar el número de árb...\n",
            "Fragmento 52: \"n\" vecinos más cercanos para el vector especifica...\n",
            "Fragmento 53: varios árboles y agrupa los resultados. por lo tan...\n",
            "Fragmento 54: datos y es particularmente útil para casos donde s...\n",
            "Fragmento 55: con solo un vector (o unos pocos vectores). esto p...\n",
            "Fragmento 56: en la distancia l2, mientras que indexivfflat es u...\n",
            "Fragmento 57: puede realizar una búsqueda para encontrar los k v...\n",
            "Fragmento 58: vector podría representar un documento, una imagen...\n",
            "Fragmento 59: casos de uso.\n",
            "ventajas de faiss:\n",
            "•rapidez: faiss e...\n",
            "Fragmento 60: # !pip install faiss-gpu # versión para gpu # !pip...\n",
            "Fragmento 61: automático.\" \"el procesamiento de lenguaje natural...\n",
            "Fragmento 62: embedqueriesnumpy # búsqueda con faiss k = 2 # núm...\n",
            "Fragmento 63: [\n",
            "]\n",
            "]\n",
            "}\n",
            "{\n",
            "[\n",
            "]\n",
            "[\n",
            "]\n",
            ":\n",
            "}\n",
            ")\n",
            "(\n",
            ")\n",
            "y el resultado será:\n",
            "c...\n",
            "Fragmento 64: 2. bases de datos vectoriales\n",
            "las bases de datos d...\n",
            "Fragmento 65: por sus siglas en inglés), confiamos en esa capaci...\n",
            "Fragmento 66: proceso en marcha que decida lo más rápidamente po...\n",
            "Fragmento 67: de mapear el significado detrás de las palabras y ...\n",
            "Fragmento 68: llm alcanzan los límites de su conocimiento:\n",
            "cosas...\n",
            "Fragmento 69: respuesta corta: los modelos tienen un límite, un ...\n",
            "Fragmento 70: tokens, mientras que el llm de código abierto llam...\n",
            "Fragmento 71: incluso reorganizar la información dentro del prom...\n",
            "Fragmento 72: proporcionando a nuestro modelo y cómo estructuram...\n",
            "Fragmento 73: relevante.\n",
            "¿cómo nos ayudan exactamente las bases ...\n",
            "Fragmento 74: esfuerzo.vector databases and their components\n",
            "par...\n",
            "Fragmento 75: elegir:tipos de bases de datos\n",
            "las bases de datos ...\n",
            "Fragmento 76: de encontrar lo que estamos buscando. por ejemplo,...\n",
            "Fragmento 77: ejemplo, es la búsqueda de similitud vectorial de ...\n",
            "Fragmento 78: y puede manejar conjuntos de vectores de cualquier...\n",
            "Fragmento 79: chroma y cómo llenarla con datos vectoriales. si b...\n",
            "Fragmento 80: en términos de distancia (por ejemplo, distancia e...\n",
            "Fragmento 81: técnicas especiales de indexación, como árboles de...\n",
            "Fragmento 82: coseno, para calcular similitudes.\n",
            "6.integración c...\n",
            "Fragmento 83: restaurar y proteger los datos.\n",
            "8.distribución y p...\n",
            "Fragmento 84: agregaciones y búsquedas basadas en texto.\n",
            "10.apli...\n",
            "Fragmento 85: de lenguaje de gran tamaño. la base de datos facil...\n",
            "Fragmento 86: 3.buscar embeddings.\n",
            "chromadb es sencillo de usar ...\n",
            "Fragmento 87: chromadbclient collection = clientcreate_collectio...\n",
            "Fragmento 88: \"este es un documento sobre gatos\" \"este es un doc...\n",
            "Fragmento 89: vectorización e indexación automáticamente sin nin...\n",
            "Fragmento 90: [[{'categoria': 'vehículo'}]], 'embeddings': none,...\n",
            "Fragmento 91: cargar universal sentence encoder embed =\n",
            "hubload\"...\n",
            "Fragmento 92: semánticos representan el significado de un texto....\n",
            "Fragmento 93: embedding_consulta = embedconsultanumpytolist resu...\n",
            "Fragmento 94: natural es un subcampo de la ia.', 'los embeddings...\n",
            "Fragmento 95: previamente debemos calcular los embeddings de nue...\n",
            "Fragmento 96: 3. knowledge graphs ( )\n",
            "grafos de conocimiento\n",
            "¿qu...\n",
            "Fragmento 97: •spo: <sujeto, predicado, objeto>\n",
            "los hechos conti...\n",
            "Fragmento 98: agregar más hechos o relaciones:\n",
            "a continuación se...\n",
            "Fragmento 99: ¿por qué un grafo de conocimiento?\n",
            "esta es la prim...\n",
            "Fragmento 100: •modelar información del mundo real: más cercano a...\n",
            "Fragmento 101: estructuradas como datos de texto.\n",
            "•elimina redund...\n",
            "Fragmento 102: inherentemente lento).¿cómo usar kg?\n",
            "los grafos de...\n",
            "Fragmento 103: panel de conocimiento a la derecha. el panel conti...\n",
            "Fragmento 104: ejemplo de panel de conocimiento basado en un graf...\n",
            "Fragmento 105: considerar información adicional sobre el usuario ...\n",
            "Fragmento 106: podrían generarse.\n",
            "“avatar” podría ser recomendada...\n",
            "Fragmento 107: podemos aprovechar los algoritmos basados en kg pa...\n",
            "Fragmento 108: información de alguna fuente externa. los nodos no...\n",
            "Fragmento 109: rápidamente algunas reglas y formas en que un kg p...\n",
            "Fragmento 110: contienen hechos de todos tipos y formas. algunos ...\n",
            "Fragmento 111: para alimentar su propio kg. en 2015, finalmente s...\n",
            "Fragmento 112: wordnet y geonames.\n",
            "yago\n",
            "linked data quality of db...\n",
            "Fragmento 113: gráficos o bloques de texto. cubriremos algunos pa...\n",
            "Fragmento 114: relation, tail). dado que estamos procesando texto...\n",
            "Fragmento 115: encontrar la relación entre cualquier par de entid...\n",
            "Fragmento 116: einstein” también puede escribirse como “albert e....\n",
            "Fragmento 117: ontología del grafo de conocimiento\n",
            "en ciencias de...\n",
            "Fragmento 118: web semántica, se crean ontologías para limitar la...\n",
            "Fragmento 119: del mundo.\n",
            "el  (rdf, por sus siglas en inglés) y e...\n",
            "Fragmento 120: \"doctor\" y \"enfermedad\". son los bloques de constr...\n",
            "Fragmento 121: •axiomas y restricciones: estas son como las regla...\n",
            "Fragmento 122: •inferencia: las acciones de los personajes conduc...\n",
            "Fragmento 123: creación y gestión de la web semántica. \n",
            "este marc...\n",
            "Fragmento 124: ◦sujeto: es el recurso que se está describiendo.\n",
            "◦...\n",
            "Fragmento 125: •formatos de serialización: aunque rdf define la e...\n",
            "Fragmento 126: aplicaciones, desde la gestión de bibliotecas y mu...\n",
            "Fragmento 127: representar semánticamente para su posterior uso e...\n",
            "Fragmento 128: el etiquetado pos nos permite identificar \"juan\" c...\n",
            "Fragmento 129: display html nlp = spacyload\"es_core_news_md\" sent...\n",
            "Fragmento 130: extraer los hechos y transformarlos en grafos de c...\n",
            "Fragmento 131: relaciones de un documento def extract_entities_re...\n",
            "Fragmento 132: == \"nmod\" prep_obj = childtext # detectar preposic...\n",
            "Fragmento 133: \"maría quiere a carlos\" \"sofía come la cena\" \"juan...\n",
            "Fragmento 134: edge_labelsentities0 entities1 = relations0 # dibu...\n",
            "Fragmento 135: )\n",
            ":\n",
            ":\n",
            ".\n",
            ":\n",
            ".\n",
            ".\n",
            ":\n",
            ".\n",
            ".\n",
            ":\n",
            ".\n",
            ".\n",
            ":\n",
            ".\n",
            ":\n",
            ".\n",
            ".\n",
            ":\n",
            ".\n",
            ":\n",
            ".\n",
            ":\n",
            "(\n",
            ",\n",
            "...\n",
            "Fragmento 136: inicia cargando un modelo lingüístico en español q...\n",
            "Fragmento 137: dirigido donde cada nodo representa una entidad (p...\n",
            "Fragmento 138: análisis.\n",
            "exportar rdf\n",
            "supongamos que queremos exp...\n",
            "Fragmento 139: = edge relation_name = edge_labelsedge subject = u...\n",
            "Fragmento 140: <?xml version=\"1.0\" encoding=\"utf-8\"?> rdf\n",
            "ns1http...\n",
            "Fragmento 141: resourcehttp://example.org/maría description\n",
            "descr...\n",
            "Fragmento 142: =\n",
            "\"\n",
            "\"\n",
            ">\n",
            "<\n",
            "ns1:\n",
            "rdf:\n",
            "=\n",
            "\"\n",
            "\"\n",
            "/>\n",
            "<\n",
            "ns1:\n",
            "rdf:\n",
            "=\n",
            "\"\n",
            "\"\n",
            "/>\n",
            "...\n",
            "Fragmento 143: rdf for edge in gedges subject_name object_name = ...\n",
            "Fragmento 144: ]\n",
            "(\n",
            ")\n",
            "(\n",
            ")\n",
            "(\n",
            ")\n",
            ".\n",
            "(\n",
            "(\n",
            ",\n",
            ",\n",
            ")\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            "(\n",
            ")\n",
            "(\n",
            ",\n",
            ")\n",
            ":\n",
            ".\n",
            "(\n",
            "...\n",
            "Fragmento 145: otras herramientas, por ejemplo con esta página: \n",
            "...\n",
            "Fragmento 146: para ser utilizadas con sistemas transaccionales (...\n",
            "Fragmento 147: está optimizado y diseñado para almacenar y gestio...\n",
            "Fragmento 148: sin índices, lo que significa que los nodos conect...\n",
            "Fragmento 149: adyacencia sin índices, y por lo tanto, utilizamos...\n",
            "Fragmento 150: rendimiento y escalabilidad. la ventaja del almace...\n",
            "Fragmento 151: las relaciones son ciudadanos de primera clase del...\n",
            "Fragmento 152: asemejan estrechamente a nuestro dominio del probl...\n",
            "Fragmento 153: •apache tinkerpop - \n",
            "tinkerpop\n",
            "•dgraph - \n",
            "dgraph\n",
            "•...\n",
            "Fragmento 154: una base de datos de grafos proporcione una técnic...\n",
            "Fragmento 155: cuando se implementa en un grafo, y cuya latencia ...\n",
            "Fragmento 156: datos relacionales y almacenes nosql. en contraste...\n",
            "Fragmento 157: proporcional solo al tamaño de la parte del grafo ...\n",
            "Fragmento 158: complejidades de los datos. las bases de datos de ...\n",
            "Fragmento 159: la aplicación existentes. estas cosas generalmente...\n",
            "Fragmento 160: tendemos a realizar menos migraciones, reduciendo ...\n",
            "Fragmento 161: elegante. en particular, la naturaleza libre de es...\n",
            "Fragmento 162: en el mundo relacional. pero esto no es un riesgo;...\n",
            "Fragmento 163: desarrollo de software ágil y dirigido por pruebas...\n",
            "Fragmento 164: codificar formularios en papel y estructuras tabul...\n",
            "Fragmento 165: desambiguar la semántica de las relaciones que con...\n",
            "Fragmento 166: en el mundo relacional en un incremento de uniones...\n",
            "Fragmento 167: con metadatos de claves foráneas.\n",
            "•las restriccion...\n",
            "Fragmento 168: cliente?\" es relativamente barato en comparación c...\n",
            "Fragmento 169: conectados. para entender el coste de realizar con...\n",
            "Fragmento 170: personfriendfriendid = p1id join person p2 on pers...\n",
            "Fragmento 171: select p1person from person p1 join personfriend o...\n",
            "Fragmento 172: todas las filas en la tabla personfriend.\n",
            "podemos ...\n",
            "Fragmento 173: para esto, por ejemplo, oracle tiene una función c...\n",
            "Fragmento 174: de los amigos de alice, y no profundiza más en la ...\n",
            "Fragmento 175: trabajamos en contra de la corriente cada vez que ...\n",
            "Fragmento 176: casos excepcionales, todo porque no hay un esquema...\n",
            "Fragmento 177: usuarios, inferimos dependencias semánticas entre ...\n",
            "Fragmento 178: conexiones entre elementos. en contraste con las t...\n",
            "Fragmento 179: conexiones entre entidades no muestran uniformidad...\n",
            "Fragmento 180: flexibilidad del modelo de grafo nos ha permitido ...\n",
            "Fragmento 181: con alguien más; incluso podemos ver los elementos...\n",
            "Fragmento 182: usuarios, mientras que otros representan pedidos o...\n",
            "Fragmento 183: usuario. las etiquetas también proporcionan un pun...\n",
            "Fragmento 184: del modelo de datos, la mayoría de las operaciones...\n",
            "Fragmento 185: dominio por la red social, veremos que experimenta...\n",
            "Fragmento 186: vecinos y otras personas similares a él. con este ...\n",
            "\n",
            "Fragmentos de la Unidad 6:\n",
            "Fragmento 1: unidad 6 - chatbots y sistemas\n",
            "de diálogo\n",
            "1. chatb...\n",
            "Fragmento 2: usuarios. a menudo se les asigna tareas específica...\n",
            "Fragmento 3: las diferencias entre estos términos:1.chatbots:\n",
            "•...\n",
            "Fragmento 4: mensajería para asistencia al cliente, faqs, y par...\n",
            "Fragmento 5: artificial, como el aprendizaje automático y la co...\n",
            "Fragmento 6: puede adaptarse y cambiar según la entrada del usu...\n",
            "Fragmento 7: asistentes personales virtuales.\n",
            "los tres términos...\n",
            "Fragmento 8: conversacionales que utilizan ia para un entendimi...\n",
            "Fragmento 9: eliza\n",
            "joseph weizenbaum\n",
            "eliza \n",
            "en 1972,  se convir...\n",
            "Fragmento 10: en 2016, la adopción generalizada de chatbots expl...\n",
            "Fragmento 11: aplicaciones que van desde el servicio al cliente ...\n",
            "Fragmento 12: 2017: aparición de los transformers\n",
            "•en junio de 2...\n",
            "Fragmento 13: plazo (lstm).\n",
            "•los transformers marcaron el comien...\n",
            "Fragmento 14: máquinas para comprender el contexto en el texto.\n",
            "...\n",
            "Fragmento 15: y capacidad, generando texto que a menudo era indi...\n",
            "Fragmento 16: motores de búsqueda y más.\n",
            "•los chatbots mejorados...\n",
            "Fragmento 17: •gpt-4: mientras que gpt-3.5 solo acepta peticione...\n",
            "Fragmento 18: de lenguaje por inteligencia artificial, si no tam...\n",
            "Fragmento 19: clasificaciones más comunes:\n",
            "1.según la capacidad ...\n",
            "Fragmento 20: las preguntas de los usuarios. estos chatbots pued...\n",
            "Fragmento 21: •chatbots de ventas y marketing: ayudan a guiar a ...\n",
            "Fragmento 22: mensajería populares como whatsapp, facebook messe...\n",
            "Fragmento 23: •chatbots multimodales: combinan múltiples formas ...\n",
            "Fragmento 24: de persona.\n",
            "chatbots basado en reglas\n",
            "como su nomb...\n",
            "Fragmento 25: chatbots basados en reglas se guían por un árbol d...\n",
            "Fragmento 26: definidas.los chatbots basados en reglas se utiliz...\n",
            "Fragmento 27: utilizan chatbots basados en reglas para aumentar ...\n",
            "Fragmento 28: un rechazo en algunos usuarios, ya que no se perci...\n",
            "Fragmento 29: ¡es un placer ayudarte!'  # función para responder...\n",
            "Fragmento 30: placer ayudarte.\" break response = respondmy_input...\n",
            "Fragmento 31: spacy import random # cargar el modelo preentrenad...\n",
            "Fragmento 32: productos con un 15% de descuento!\" \"por la compra...\n",
            "Fragmento 33: con un precio de $datos_producto'precio', \" f\"y ac...\n",
            "Fragmento 34: producto, usar spacy para ner doc = nlpmessage ent...\n",
            "Fragmento 35: nuestras promociones.\" while true user_input = inp...\n",
            "Fragmento 36: :\n",
            "(\n",
            ")\n",
            "(\n",
            ".\n",
            ")\n",
            ":\n",
            "(\n",
            ")\n",
            "(\n",
            ")\n",
            ":\n",
            "(\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            ":\n",
            "(\n",
            ")\n",
            "(\n",
            ")\n",
            "(\n",
            ",\n",
            ")\n",
            "...\n",
            "Fragmento 37: muy específicos. si un usuario no escribe exactame...\n",
            "Fragmento 38: palabras compuestas, etc.3.mantenimiento: a medida...\n",
            "Fragmento 39: \"aspiradora\". esto le permite manejar variaciones ...\n",
            "Fragmento 40: usuario.\n",
            "3.escalabilidad y mantenimiento: al depen...\n",
            "Fragmento 41: chatbots basados en ia\n",
            "los chatbots basados en ia,...\n",
            "Fragmento 42: neuronales recurrentes (rnn), las redes neuronales...\n",
            "Fragmento 43: •aprenden a predecir la siguiente palabra en una s...\n",
            "Fragmento 44: comprensión y generación de lenguaje natural:\n",
            "•los...\n",
            "Fragmento 45: adaptándose a los patrones de habla de los usuario...\n",
            "Fragmento 46: emocional y consejos, aunque con ciertas limitacio...\n",
            "Fragmento 47: contexto o la intención, llevando a respuestas ina...\n",
            "Fragmento 48: por ejemplo, en la generación de texto, un prompt ...\n",
            "Fragmento 49: prompts. la calidad y claridad de un prompt pueden...\n",
            "Fragmento 50: al trabajar con prompts, interactuamos con el llm ...\n",
            "Fragmento 51: fomenta resultados más diversos o creativos. esenc...\n",
            "Fragmento 52: consideremos la frase \"el cielo es\". cuando lees e...\n",
            "Fragmento 53: probabilidades para todas las diferentes palabras ...\n",
            "Fragmento 54: permitiéndole usar palabras con probabilidades más...\n",
            "Fragmento 55: antes de que los delfines decidan renunciar a su b...\n",
            "Fragmento 56: sucesivamente, con diferentes probabilidades. pued...\n",
            "Fragmento 57: caso).top-p es similar, pero elige entre los token...\n",
            "Fragmento 58: inferior de las salidas probables.\n",
            "max length (máx...\n",
            "Fragmento 59: entonces, por ejemplo, si le damos al modelo el pr...\n",
            "Fragmento 60: los ejemplos y luego usamos esa cadena como secuen...\n",
            "Fragmento 61: tokens que aparecen más una penalización mayor.\n",
            "pr...\n",
            "Fragmento 62: respuesta. si queremos que el modelo genere texto ...\n",
            "Fragmento 63: resultados pueden variar dependiendo de la versión...\n",
            "Fragmento 64: obtener mejores resultados.\n",
            "comencemos repasando u...\n",
            "Fragmento 65: lejana de la tarea que queremos lograr.\n",
            "este ejemp...\n",
            "Fragmento 66: (\"completa la oración\"). este enfoque de diseñar p...\n",
            "Fragmento 67: formateo de prompts\n",
            "hemos probado un prompt muy si...\n",
            "Fragmento 68: respuesta sin ningún ejemplo o demostración sobre ...\n",
            "Fragmento 69: prompts few-shot de la siguiente manera:\n",
            "<question...\n",
            "Fragmento 70: prompt:\n",
            "texto: ¡esto es malo! etiqueta: positivo t...\n",
            "Fragmento 71: demostraciones.\n",
            "elementos de los prompts\n",
            "a medida ...\n",
            "Fragmento 72: hacia respuestas mejores.\n",
            "datos de entrada - la en...\n",
            "Fragmento 73: comenzar simple\n",
            "a medida que comiences con el dise...\n",
            "Fragmento 74: una tarea grande que involucre muchas sub-tareas d...\n",
            "Fragmento 75: \"resume\", \"traduce\", \"ordena\", etc.tengamos en cue...\n",
            "Fragmento 76: algunas recomendaciones indican conveniente coloca...\n",
            "Fragmento 77: resultados. esto es particularmente importante cua...\n",
            "Fragmento 78: hay limitaciones respecto a cuán larga puede ser (...\n",
            "Fragmento 79: un texto.\n",
            "prompt:extraer cantidades de conjuntos d...\n",
            "Fragmento 80: undiales debatirán los avances en la lucha contra ...\n",
            "Fragmento 81: crear descripciones imprecisas. a menudo es mejor ...\n",
            "Fragmento 82: no está claro en el prompt anterior cuántas frases...\n",
            "Fragmento 83: decir lo que se debe hacer en su lugar. esto fomen...\n",
            "Fragmento 84: miende una película basada en mis intereses. agent...\n",
            "Fragmento 85: evitar solicitar información personal. si el agent...\n",
            "Fragmento 86: algunos de los ejemplos anteriores fueron tomados ...\n",
            "Fragmento 87: tareas:\n",
            "resumen de textosuna de las tareas estánda...\n",
            "Fragmento 88: indicación como esta:\n",
            "prompt:\n",
            "explique los antibió...\n",
            "Fragmento 89: vía intravenosa. no son eficaces contra las infecc...\n",
            "Fragmento 90: demasiada información y quieres resumirla aún más....\n",
            "Fragmento 91: e píldoras, cápsulas o soluciones líquidas o, a ve...\n",
            "Fragmento 92: istencia a los antibióticos.\n",
            "sin prestar demasiada...\n",
            "Fragmento 93: (nlp).\n",
            "aquí hay un ejemplo de una indicación que e...\n",
            "Fragmento 94: res para que examinen los manuscritos con más aten...\n",
            "Fragmento 95: anterior es chatgpt.\n",
            "hay muchas maneras en las que...\n",
            "Fragmento 96: fuente del párrafo: \n",
            "chatgpt: cinco prioridades pa...\n",
            "Fragmento 97: en una buena práctica ya que cuanto más específico...\n",
            "Fragmento 98: farmacéutica de nueva jersey llamada ortho pharmac...\n",
            "Fragmento 99: para uso humano. pregunta: ¿de qué se obtuvo origi...\n",
            "Fragmento 100: usar en un prompt. otros elementos que podemos pro...\n",
            "Fragmento 101: necesitamos es que el modelo dé la etiqueta en el ...\n",
            "Fragmento 102: prompt:\n",
            "clasifica el texto en neutro, negativo o p...\n",
            "Fragmento 103: continuación e identifiquemos el problema:\n",
            "prompt:...\n",
            "Fragmento 104: descripciones a las etiquetas o agregar más ejempl...\n",
            "Fragmento 105: por ejemplo, pensemos un sistema conversacional qu...\n",
            "Fragmento 106: eres? ai: ¡saludo! soy asistente de investigación ...\n",
            "Fragmento 107: intensa gravedad de la singularidad atrae toda la ...\n",
            "Fragmento 108: os estudiantes de primaria. humano: hola, ¿quién e...\n",
            "Fragmento 109: n. esto crea un punto en el espacio-tiempo con una...\n",
            "Fragmento 110: prompt:\n",
            "/* programa que pregunta al usuario su nom...\n",
            "Fragmento 111: pueden ser los llms, con un poco más de esfuerzo e...\n",
            "Fragmento 112: ormática');\n",
            "en este caso, proporcionamos datos sob...\n",
            "Fragmento 113: interés es poder dialogar con estos sistemas desde...\n",
            "Fragmento 114: de texto y modelos conversacionales. son dos categ...\n",
            "Fragmento 115: coherencia como la diversidad del texto a través d...\n",
            "Fragmento 116: las empresas mantener la privacidad de sus datos (...\n",
            "Fragmento 117: como el chatgpt (que es la interfaz de usuario par...\n",
            "Fragmento 118: una variedad de formatos y estilos, incluyendo per...\n",
            "Fragmento 119: estilos.\n",
            "4.menor especialización en diálogos: aunq...\n",
            "Fragmento 120: open-assistant\n",
            ").\n",
            "•generación de código\n",
            "un modelo ...\n",
            "Fragmento 121: una vez\" y proceder a crear un texto similar a una...\n",
            "Fragmento 122: ”continuar una historia dadas las primeras oracion...\n",
            "Fragmento 123: documentos, desde código hasta historias.•modelos ...\n",
            "Fragmento 124: modelos conversacionales\n",
            "el modelado de respuestas...\n",
            "Fragmento 125: mantener diálogos coherentes y contextuales.\n",
            "2.uso...\n",
            "Fragmento 126: el contexto y mantener la coherencia en una serie ...\n",
            "Fragmento 127: información en el formato adecuado para funcionar ...\n",
            "Fragmento 128: a cada modelo específico, y que nos facilitan la u...\n",
            "Fragmento 129: funcionalidades avanzadas de manera rápida y senci...\n",
            "Fragmento 130: model=model tokenizer=tokenizer # generar texto a ...\n",
            "Fragmento 131: the same what happens next? the robotic revolution...\n",
            "Fragmento 132: be human\n",
            "[\n",
            "]\n",
            ":\n",
            ",\n",
            ".\n",
            ".\n",
            ",\n",
            "[\n",
            "]\n",
            ":\n",
            ",\n",
            ".\n",
            ".\n",
            ",\n",
            "en este ejemp...\n",
            "Fragmento 133: pipeline conversacional\n",
            "del mismo modo, podemos ut...\n",
            "Fragmento 134: model=model tokenizer=tokenizer # crear un objeto ...\n",
            "Fragmento 135: ,\n",
            ",\n",
            ",\n",
            ".\n",
            "(\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            "(\n",
            ",\n",
            ",\n",
            ")\n",
            "(\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            "(\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            "(\n",
            ")\n",
            "...\n",
            "Fragmento 136: mensaje del usuario a la misma conversación, y se ...\n",
            "Fragmento 137: pipeline de generación de texto a texto (text2text...\n",
            "Fragmento 138: life, the universe and everything\" text2text_gener...\n",
            "Fragmento 139: ).\n",
            "text2text-generation\n",
            "https://huggingface.co/mod...\n",
            "Fragmento 140: pueden abarcar desde preguntas y respuestas hasta ...\n",
            "Fragmento 141: complejas, en la generación de respuestas más rele...\n",
            "Fragmento 142: instrucciones (instruction-following), se llama al...\n",
            "Fragmento 143: de conjunto de datos de instrucciones (por ejemplo...\n",
            "Fragmento 144: the request. ### instruction: {instruction} ### in...\n",
            "Fragmento 145: contenido, siendo este último el texto real del me...\n",
            "Fragmento 146: \"¡encantado de conocerte!\"} ]\n",
            "esta secuencia de me...\n",
            "Fragmento 147: [user] ¡hola! [/user] [asst] ¡encantado de conocer...\n",
            "Fragmento 148: anteriores, no son inventados; sino que son reales...\n",
            "Fragmento 149: modelo. si no lo está, puede dificultarse el uso d...\n",
            "Fragmento 150: correcto, y será muy difícil depurar la causa.las ...\n",
            "Fragmento 151: \"usuario : \" }} {% else %} {{ \"bot : \" }} {{ messa...\n",
            "Fragmento 152: message['content'] + '' + '\\n'}}\" \"{% endfor %}\"\n",
            "a...\n",
            "Fragmento 153: específicos.\n",
            "jinja\n",
            "chatml \n",
            "para desarrollar un sis...\n",
            "Fragmento 154: historias de misterio.\"}, {\"role\": \"user\", \"conten...\n",
            "Fragmento 155: completar la frase: el cielo está assistant: -----...\n",
            "Fragmento 156: nuestro modelo, es usando la librería llm-template...\n",
            "Fragmento 157: ,\n",
            "[\n",
            "{\n",
            ":\n",
            ",\n",
            ":\n",
            "}\n",
            ",\n",
            "{\n",
            ":\n",
            ",\n",
            ":\n",
            "}\n",
            "]\n",
            "(\n",
            ")\n",
            "(\n",
            ",\n",
            ")\n",
            "(\n",
            ".\n",
            "(\n",
            ",\n",
            ")\n",
            ")\n",
            "...\n",
            "Fragmento 158: gpus de alto rendimiento. esto puede ser costoso y...\n",
            "Fragmento 159: 4.mantenimiento y actualizaciones: el mantenimient...\n",
            "Fragmento 160: configuración inicial y el mantenimiento técnico l...\n",
            "Fragmento 161: esfuerzo adicional por parte del usuario.\n",
            "4.sin ne...\n",
            "Fragmento 162: 7.privacidad de datos: la privacidad de los datos ...\n",
            "Fragmento 163: import template def zephyr_chat_templatemessages\n",
            "a...\n",
            "Fragmento 164: message['content'] }}</s>\\n\" template_str += \"{% e...\n",
            "Fragmento 165: add_generation_prompt=add_generation_prompt # tu c...\n",
            "Fragmento 166: chat_prompt = \"role\" \"system\" \"content\" \"eres un e...\n",
            "Fragmento 167: # realizamos la solicitud post response = requests...\n",
            "Fragmento 168: <|user|>completar la frase: el cielo está</s> <|as...\n",
            "Fragmento 169: estrellas\". esto puede sugerir que el escritor se ...\n",
            "Fragmento 170: desee para su escritura de misterio.\n",
            "4. rag (retri...\n",
            "Fragmento 171: para lograr un amplio espectro de conocimiento gen...\n",
            "Fragmento 172: por lo tanto, es importante cerrar la brecha entre...\n",
            "Fragmento 173: que la hace menos ágil para adaptarse a la informa...\n",
            "Fragmento 174: fácilmente.\n",
            "\"generación con\n",
            "recuperación aumentada...\n",
            "Fragmento 175: examen con libro abierto es que el examen se centr...\n",
            "Fragmento 176: implícitamente en los pesos de la red neuronal.\n",
            "•c...\n",
            "Fragmento 177: adicional en la base de datos vectorial. esto perm...\n",
            "Fragmento 178: para crear un sistema de consulta de historia arge...\n",
            "Fragmento 179: sobre historia argentina url =\n",
            "'https://drive.goog...\n",
            "Fragmento 180: oslistdircarpeta_origen ruta_origen = ospathjoinca...\n",
            "Fragmento 181: esos documentos, crear los embeddings y almacenarl...\n",
            "Fragmento 182: necesarias, que se mencionan abajo):\n",
            "# !pip instal...\n",
            "Fragmento 183: formatter conversation # función para aplicar el t...\n",
            "Fragmento 184: none try # tu clave api de hugging face. busca en ...\n",
            "Fragmento 185: https://huggingface.co/docs/transformers/main_clas...\n",
            "Fragmento 186: context_str str text_qa_prompt_tmpl =  \"la informa...\n",
            "Fragmento 187: ,\n",
            ":\n",
            ",\n",
            ":\n",
            ",\n",
            ":\n",
            "}\n",
            "}\n",
            ".\n",
            "(\n",
            ",\n",
            ",\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            "[\n",
            "]\n",
            "[\n",
            "]\n",
            "[\n",
            "(\n",
            ")\n",
            ":\n",
            "]\n",
            "...\n",
            "\n",
            "Fragmentos de la Unidad 7:\n",
            "Fragmento 1: unidad 7 - agentes autónomos\n",
            "y sistemas inteligent...\n",
            "Fragmento 2: adquirir, retener y usar el conocimiento para reso...\n",
            "Fragmento 3: operar de forma autónoma, percibir su entorno, per...\n",
            "Fragmento 4: muestra cómo nosotros, como seres humanos, aprende...\n",
            "Fragmento 5: el punto de vista del nlp, nos interesa diseñar un...\n",
            "Fragmento 6: consideremos una tarea concreta. supongamos que te...\n",
            "Fragmento 7: sistema vamos a construir, cómo puede estructurars...\n",
            "Fragmento 8: múltiples componentes que deben combinarse para cr...\n",
            "Fragmento 9: inteligentes, aquí hay una de geoff hulten:\n",
            "”los s...\n",
            "Fragmento 10: books/blob/master/book/building intelligent system...\n",
            "Fragmento 11: ejemplo, los automóviles autónomos, donde el objet...\n",
            "Fragmento 12: presenta una visión general de alto nivel de un si...\n",
            "Fragmento 13: usuario final. estos resultados pueden ser sugeren...\n",
            "Fragmento 14: lograr tareas complejas. para que estos sistemas i...\n",
            "Fragmento 15: pertenece a esta categoría. un sistema asesor inte...\n",
            "Fragmento 16: métodos prescriptivos (por ejemplo, asignación de ...\n",
            "Fragmento 17: para tratar al paciente. la siguiente figura repre...\n",
            "Fragmento 18: debido a los tipos de aplicaciones complejas que p...\n",
            "Fragmento 19: prompt:\n",
            "¿cuánto es 9.000 * 9.000?\n",
            "salida:\n",
            "el resul...\n",
            "Fragmento 20: 7, 1. resuelva dividiendo el problema en pasos. pr...\n",
            "Fragmento 21: a es 41, y 41 es un número impar. por lo tanto, la...\n",
            "Fragmento 22: por lo que son capaces de realizar algunas tareas ...\n",
            "Fragmento 23: capacidad de zero-shot en acción.la sintonización ...\n",
            "Fragmento 24: ejemplos en el prompt, lo que conduce a la generac...\n",
            "Fragmento 25: demostraciones en el prompt para dirigir al modelo...\n",
            "Fragmento 26: la clasificación faltante. texto: hoy el clima est...\n",
            "Fragmento 27: complejas. vamos a demostrar por qué es este el ca...\n",
            "Fragmento 28: sistemas sino que también existe la necesidad de u...\n",
            "Fragmento 29: 3, 24. a: la respuesta es verdadero. los números i...\n",
            "Fragmento 30: tipo de tarea que hemos introducido implica alguno...\n",
            "Fragmento 31: tareas. cuando los prompts de zero-shot y few-shot...\n",
            "Fragmento 32: pasos de razonamiento intermedios. podemos combina...\n",
            "Fragmento 33: 9, 4, 8, 12, 24. a: sumar todos los números impare...\n",
            "Fragmento 34: este grupo suman a un número par: 15, 32, 5, 13, 8...\n",
            "Fragmento 35: 2, 1. a: sumar todos los números impares (9, 15, 1...\n",
            "Fragmento 36: fuente: \n",
            "kojima et al. (2022)\n",
            "una idea reciente qu...\n",
            "Fragmento 37: anas me quedé?\n",
            "output:11 manzanas\n",
            "la respuesta es ...\n",
            "Fragmento 38: s, así que ahora tenías 11 manzanas. finalmente, t...\n",
            "Fragmento 39: intercalada.\n",
            "yao et al., 2022\n",
            "la generación de ras...\n",
            "Fragmento 40: objetivas.\n",
            "los resultados muestran que react puede...\n",
            "Fragmento 41: ¿cómo funciona react?react se inspira en las siner...\n",
            "Fragmento 42: actualizar sus conocimientos puede provocar proble...\n",
            "Fragmento 43: entornos externos (por ejemplo, wikipedia) para in...\n",
            "Fragmento 44: respaldar el razonamiento, mientras que el razonam...\n",
            "Fragmento 45: figura anterior. los pensamientos de forma libre s...\n",
            "Fragmento 46: benchmarks obtenidos son los siguientes:\n",
            "fever\n",
            "yao...\n",
            "Fragmento 47: más información\n",
            "react: synergizing reasoning and a...\n",
            "Fragmento 48: el rendimiento en  e hizo que el modelo fuera más ...\n",
            "Fragmento 49: (dpo)\n",
            "mt bench\n",
            "informe técnico\n",
            "veamos como se comp...\n",
            "Fragmento 50: zephyr_chat_templatemessages add_generation_prompt...\n",
            "Fragmento 51: max_words_per_line linesappend' 'joincurrent_line ...\n",
            "Fragmento 52: try prompt_formatted str = zephyr_chat_templatemes...\n",
            "Fragmento 53: https://huggingface.co/docs/transformers/main_clas...\n",
            "Fragmento 54: print'pregunta: ' word_wrappregunta 24 print'\\nres...\n",
            "Fragmento 55: por qué?\" \"¿en qué se parece el rol de una membran...\n",
            "Fragmento 56: cometiendo?\"  solve_questionspreguntas_de_logica\n",
            "p...\n",
            "Fragmento 57: ,\n",
            ":\n",
            "{\n",
            ":\n",
            ",\n",
            ":\n",
            ",\n",
            ":\n",
            ",\n",
            ":\n",
            "}\n",
            "}\n",
            ".\n",
            "(\n",
            ",\n",
            ",\n",
            ")\n",
            ".\n",
            "(\n",
            ")\n",
            "[\n",
            "]\n",
            "[\n",
            "]\n",
            "[\n",
            "...\n",
            "Fragmento 58: enfermedad dado que dio positivo?\" \"explica la par...\n",
            "Fragmento 59: entender esta diferencia podría llevar a un error....\n",
            "Fragmento 60: explica la ambigüedad en esta oración.\" \n",
            "solve_que...\n",
            "Fragmento 61: suministrado: respuesta al principio compráste 10 ...\n",
            "Fragmento 62: manzanas 6. comiste 1 manzana 7. quedaste con 10 m...\n",
            "Fragmento 63: comiste del total para saber cuántas manzanas tien...\n",
            "Fragmento 64: manzanas que tienes luego como sabes cuántas manza...\n",
            "Fragmento 65: .\n",
            ".\n",
            ".\n",
            ".\n",
            ":\n",
            ",\n",
            ".\n",
            ",\n",
            ".\n",
            ".\n",
            ",\n",
            ",\n",
            ".\n",
            ",\n",
            ",\n",
            ".\n",
            ",\n",
            ",\n",
            ".\n",
            ":\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            "...\n",
            "Fragmento 66: otros modelos más potentes, como los basados en gt...\n",
            "Fragmento 67: pelotasdeteniscompra2latasmásdepelotasdeteniscadal...\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "import PyPDF2\n",
        "from unidecode import unidecode\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    # Extrae el texto de un archivo PDF\n",
        "    text = \"\"\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "def process_pdf_text(pdf_path):\n",
        "    # Procesa el texto extraído del PDF\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "    # Convierte todo el texto a minúsculas para uniformidad\n",
        "    text = text.lower()\n",
        "\n",
        "    # Elimina todos los caracteres que no sean letras, números o espacios\n",
        "    # Esto ayuda a estandarizar el texto y eliminar puntuación y símbolos\n",
        "    return text\n",
        "\n",
        "def split_text_with_langchain(text, chunk_size=500, chunk_overlap=50):\n",
        "    # Divide el texto en fragmentos más pequeños\n",
        "    # chunk_size: define el tamaño máximo de cada fragmento en caracteres\n",
        "    # chunk_overlap: determina cuántos caracteres se superponen entre fragmentos\n",
        "    #                esto ayuda a mantener el contexto entre fragmentos\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap,\n",
        "        length_function=len,\n",
        "    )\n",
        "    return text_splitter.split_text(text)\n",
        "\n",
        "# Crear un diccionario global para almacenar los fragmentos sin stopwords\n",
        "global fragments_dict\n",
        "fragments_dict = {}\n",
        "\n",
        "# Dividir todos los PDFs y procesa los fragmentos para eliminar stopwords\n",
        "for i, pdf_path in enumerate(pdfs, 1):\n",
        "    processed_text = process_pdf_text(pdf_path)\n",
        "    fragments = split_text_with_langchain(processed_text)\n",
        "\n",
        "    # Almacenar los fragmentos sin stopwords en el diccionario global\n",
        "    fragments_dict[f'unidad_{i}'] = fragments\n",
        "\n",
        "    print(f\"\\nFragmentos de la Unidad {i}:\")\n",
        "    for j, fragment in enumerate(fragments, 1):\n",
        "        # Muestra una vista previa de cada fragmento (primeros 50 caracteres)\n",
        "        print(f\"Fragmento {j}: {fragment[:50]}...\")\n",
        "\n",
        "# Un chunk_size mayor dará fragmentos más largos, lo que puede ser útil para mantener más contexto\n",
        "# Un chunk_overlap mayor aumentará la superposición, ayudando a preservar la continuidad entre fragmentos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxIPunB3jVSU"
      },
      "source": [
        "# Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "7f214add7db2461a8cc243c48bbfa3d4",
            "120ece9b3f6446a593e111ed7a0389e0",
            "bf7554ffbb2a47cea5d09e7685dd0ccd",
            "29094614d5654d2e92d42d80bee086dd",
            "cfdb4221714c46eb876416aab103ca86",
            "c9201ef3d7a74f0c92ea44c45bf793f7",
            "8f48b7f5ce3c4de581aa45ae1cb367ee",
            "dfb7f1b0e7a540d1bff6b613679855bd",
            "cbbd93622a8b455da0caf202f5a0ecea",
            "e1bd3f3814b14c3c85da38053bf4a353",
            "fd1bb26e66774f88bff0575aba3bfbe8",
            "5501b40abe9b4d629bf34ede2a3a8938",
            "8245d5ecaaf44746ba7f344b1bc433ef",
            "6ece6c5b130b470c8ebdd13ad1adfe3c",
            "c0b47ce6857445f787bbc144b56b9bd0",
            "24482c08d1f34d56a859603e566e62e6",
            "48474986230044c9b0426ba5e708e3c2",
            "14df48dfa56f471db2e1ca4b43e2039f",
            "6e842712cfa34092b946ec2aca4305db",
            "06752b86941e459dbda8e14574263044",
            "c0369ffe0a48470183e5e6bda13deb66",
            "2d23793641794a9f9524901c1b04ce65",
            "76953c74e0ea426b8a74ebb0484410b6",
            "62b764b18ca64bfc8c224b3ed62e42b0",
            "65db3677eba344e9b345cb18a5aa5414",
            "74b01fa8c21f4b199144c4ffaf4a27cf",
            "28bcb812edb741eba3d0c40253c10cd2",
            "8bfb779f85c04f2fa9ff29d98a03431c",
            "752d15670b3546b4a1dead2e36268b2c",
            "1009fac751e94809b256ba2f808c7be2",
            "dde79e958c5b4f6482a5069fce47f179",
            "a00ddb43af5c4d1d99cf5c0f42ec5bb5",
            "171725987a2f473fb6c8935db2978325",
            "f9065a567c134e76b291875be6e287ad",
            "28ece375895643c7a5d1c016e7d57b40",
            "c0f1f62724db451a9367649c9b962b9e",
            "d25c9af0a86f4f3cb27fa0c6f4d4ba1a",
            "2c82ff20fed042648f4f6cf8c62cbea1",
            "7c66f9c4cfba4269bb7bd6ff0d35d11d",
            "b1ae8c8c9d3b4a8288c844c3c976df9c",
            "5a012b5384f14c3394098900badc6116",
            "e6a5cc7de17c46f5b1f6aebbc5691d99",
            "27506c9e25d442869d6ffb308e3b46ae",
            "1d245798eea2474a904928b46705ec66",
            "b6773f485cb94be3b6a78ee48f9a37c7",
            "3cdfa2ac918143188e8005c9a91456d9",
            "064dbbd2131a45518fc66d3d6ef76746",
            "83578b93d5e04ad18d2d073585d656c8",
            "d273411970d949a98ec430c8db5f40c9",
            "24b637ac24c7460d844aed5d7ab39328",
            "637085cdaccf457d9c0970807d881b5e",
            "2dd91c0fe4a4483380f4da2770076c39",
            "37de6e3d25eb4ffc8ae9133109d667df",
            "2a1ef813c3c34e9aa9df65d2f276be4d",
            "15391e9e228a4d3f81be5f6b770ce404",
            "ca8e309cf0f34941b2938d5f3cf090cf",
            "d31a0e4e4a2f457c92780eda0c104060",
            "8c592e06559a40fe8fd6d795a9ab4d75",
            "14dceb684fc04aea9a13ec83c4768f91",
            "eb65f2594a3046c6a514b62377b24b54",
            "8edcf04be9e84d76b7a153a67c69914e",
            "1e85e6d52787466d820bfd4d19ac4da3",
            "6cdd667abaaf443994877301a5341e0a",
            "30e529c3c9554adbad0b0844423dc70b",
            "0f526eaabee1413e9829bab4ef0b0589",
            "af86441c56884cc885110586ad66537f"
          ]
        },
        "id": "3Y7coT_QfkUK",
        "outputId": "9f9f3069-1b68-4af6-a8b5-6526ffe98993"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f214add7db2461a8cc243c48bbfa3d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/648 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5501b40abe9b4d629bf34ede2a3a8938",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76953c74e0ea426b8a74ebb0484410b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/364 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9065a567c134e76b291875be6e287ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/242k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6773f485cb94be3b6a78ee48f9a37c7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/134 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca8e309cf0f34941b2938d5f3cf090cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/480k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Embeddings de los fragmentos de unidad_1:\n",
            "(179, 768)\n",
            "\n",
            "Embeddings de los fragmentos de unidad_2:\n",
            "(167, 768)\n",
            "\n",
            "Embeddings de los fragmentos de unidad_3:\n",
            "(185, 768)\n",
            "\n",
            "Embeddings de los fragmentos de unidad_4:\n",
            "(149, 768)\n",
            "\n",
            "Embeddings de los fragmentos de unidad_5:\n",
            "(186, 768)\n",
            "\n",
            "Embeddings de los fragmentos de unidad_6:\n",
            "(187, 768)\n",
            "\n",
            "Embeddings de los fragmentos de unidad_7:\n",
            "(67, 768)\n",
            "\n",
            "Ejemplo de embeddings para unidad_1:\n",
            "[[ 0.05367143  0.13624236 -0.31646827 ... -0.249538    0.16316204\n",
            "   0.06009699]\n",
            " [-0.20899178  0.17416608 -0.28842649 ...  0.01384886  0.10865366\n",
            "   0.35636562]\n",
            " [-0.27344424  0.12047482 -0.46065781 ...  0.03319148 -0.12157888\n",
            "   0.09256357]\n",
            " ...\n",
            " [ 0.06931979  0.19641548 -0.27520782 ... -0.25259843 -0.30628526\n",
            "  -0.11172235]\n",
            " [-0.10986084  0.2881462  -0.41449106 ... -0.09863464 -0.16996282\n",
            "   0.29158288]\n",
            " [-0.47995216  0.12194171 -0.56929469 ... -0.48056489  0.16987181\n",
            "   0.00934488]]\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertModel, BertTokenizer\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Cargar el modelo BERT en español ya que todos nuestros datos estan en español\n",
        "modelo_es = BertModel.from_pretrained('dccuchile/bert-base-spanish-wwm-cased')\n",
        "tokenizador_es = BertTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-cased')\n",
        "\n",
        "# Función que obtiene embeddings para cada texto\n",
        "def obtener_embeddings(fragmentos):\n",
        "    embeddings = []\n",
        "    for fragmento in fragmentos:\n",
        "        tokens = tokenizador_es(fragmento, truncation=True, padding=True, return_tensors='pt', max_length=512)\n",
        "        with torch.no_grad():\n",
        "            outputs = modelo_es(**tokens)\n",
        "        embedding_vector = outputs.last_hidden_state.mean(dim=1).squeeze()\n",
        "        embeddings.append(embedding_vector.tolist())\n",
        "    return embeddings\n",
        "\n",
        "# Diccionario para almacenar los embeddings\n",
        "embeddings_dict = {}\n",
        "\n",
        "# Obtener embeddings para cada unidad en el diccionario fragments_sin_stopwords_dict\n",
        "for unidad, fragmentos in fragments_dict.items():\n",
        "    embeddings = obtener_embeddings(fragmentos)\n",
        "    embeddings_dict[unidad] = embeddings\n",
        "\n",
        "    print(f\"\\nEmbeddings de los fragmentos de {unidad}:\")\n",
        "    print(np.array(embeddings).shape)\n",
        "\n",
        "# Acedemos a la los embeddings de la unidad 1 a modo de ejemplo para ver como queda\n",
        "if 'unidad_1' in embeddings_dict:\n",
        "    print(\"\\nEjemplo de embeddings para unidad_1:\")\n",
        "    print(np.array(embeddings_dict['unidad_1']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSamKWtfjXtS"
      },
      "source": [
        "# Chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46Mk4ZBggDz6",
        "outputId": "21fa8b1b-0eb3-4d10-b72b-2d8b7d440c5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número total de fragmentos: 1120\n",
            "Número total de embeddings: 1120\n",
            "Número total de IDs: 1120\n",
            "Se han agregado 1120 fragmentos a la colección de ChromaDB.\n"
          ]
        }
      ],
      "source": [
        "import chromadb\n",
        "import numpy as np\n",
        "\n",
        "# Crear el cliente y la colección de Chroma\n",
        "chroma_client = chromadb.Client()\n",
        "collection = chroma_client.create_collection(name=\"teoria\")\n",
        "\n",
        "# Unir todos los fragmentos en una sola lista\n",
        "todos_los_fragmentos = []\n",
        "todos_los_embeddings = []\n",
        "ids = []\n",
        "\n",
        "for unidad, fragmentos in fragments_dict.items():\n",
        "    todos_los_fragmentos.extend(fragmentos)\n",
        "    todos_los_embeddings.extend(embeddings_dict[unidad])\n",
        "    ids.extend([f'{unidad}_id{i+1}' for i in range(len(fragmentos))])\n",
        "\n",
        "# Comprobamos la cantidad total de fragmentos\n",
        "print(f\"Número total de fragmentos: {len(todos_los_fragmentos)}\")\n",
        "\n",
        "# Comprobamos que tenemos la misma cantidad de embeddings que de fragmentos\n",
        "print(f\"Número total de embeddings: {len(todos_los_embeddings)}\")\n",
        "\n",
        "# Comprobamos que tenemos la misma cantidad de IDs que de fragmentos\n",
        "print(f\"Número total de IDs: {len(ids)}\")\n",
        "\n",
        "# Convertimos los embeddings a una lista de listas\n",
        "embeddings_lista = [embedding.tolist() if isinstance(embedding, np.ndarray) else embedding for embedding in todos_los_embeddings]\n",
        "\n",
        "# Agregamos los embeddings a chromaDB\n",
        "collection.add(\n",
        "    embeddings=embeddings_lista,\n",
        "    documents=todos_los_fragmentos,\n",
        "    ids=ids\n",
        ")\n",
        "\n",
        "print(f\"Se han agregado {len(todos_los_fragmentos)} fragmentos a la colección de ChromaDB.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4Csr__kjZ1I"
      },
      "source": [
        "# Modelo de clasificación (PDF, CSV o Grafo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-buzJWEeKIgB"
      },
      "source": [
        "###### ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0W8uhk2PjdF6"
      },
      "outputs": [],
      "source": [
        "# Preparar los datos de entrenamiento\n",
        "prompts = [\n",
        "    # CSV (ejercicios)\n",
        "    \"Necesito una práctica sobre extracción de texto\",\n",
        "    \"Muestra un ejercicio de OCR\",\n",
        "    \"Busco un problema de dificultad media sobre procesamiento de lenguaje natural\",\n",
        "    \"¿Hay algún ejercicio sobre tokenización?\",\n",
        "    \"Quiero practicar con un ejercicio de análisis de sentimientos\",\n",
        "    \"Necesito un ejercicio práctico sobre clasificación de textos\",\n",
        "    \"Dame un problema para resolver sobre vectorización de palabras\",\n",
        "    \"Busco un ejercicio difícil de reconocimiento de entidades nombradas\",\n",
        "    \"¿Tienes algún ejercicio sobre stemming y lematización?\",\n",
        "    \"Proporciona un ejercicio de preprocesamiento de texto\",\n",
        "    \"Dame una tarea práctica de normalización de texto\",\n",
        "    \"Necesito un ejercicio para practicar la eliminación de stopwords\",\n",
        "    \"¿Hay algún problema sobre construcción de n-gramas?\",\n",
        "    \"Quiero un ejercicio de análisis de frecuencia de palabras\",\n",
        "    \"Busco una práctica de codificación one-hot para texto\",\n",
        "    \"Dame un ejercicio para implementar TF-IDF\",\n",
        "    \"Necesito una tarea sobre bag-of-words\",\n",
        "    \"¿Tienes algún problema práctico de parsing?\",\n",
        "    \"Proporciona un ejercicio de etiquetado POS\",\n",
        "\n",
        "    # Grafo (conceptos)\n",
        "    \"Explícame la relación entre tokenización y análisis sintáctico\",\n",
        "    \"¿Cómo se conecta el procesamiento de lenguaje natural con el aprendizaje automático?\",\n",
        "    \"Muestra el camino de aprendizaje para dominar NLP\",\n",
        "    \"¿Qué conceptos están relacionados con el análisis de sentimientos?\",\n",
        "    \"Describe la estructura de un pipeline de NLP\",\n",
        "    \"¿Cuáles son los componentes principales del procesamiento de lenguaje natural?\",\n",
        "    \"Explica la conexión entre word embeddings y redes neuronales\",\n",
        "    \"¿Cómo se relacionan la lingüística computacional y el NLP?\",\n",
        "    \"Muestra los prerequisitos para aprender procesamiento de lenguaje natural\",\n",
        "    \"¿Qué técnicas de deep learning se aplican en NLP?\",\n",
        "    \"Explica el concepto de parsing en NLP\",\n",
        "    \"¿Cuál es la diferencia entre procesamiento de lenguaje natural y comprensión del lenguaje natural?\",\n",
        "    \"Describe los diferentes niveles de análisis en NLP\",\n",
        "    \"¿Qué papel juega la semántica en el procesamiento de lenguaje natural?\",\n",
        "    \"Explica el concepto de desambiguación en NLP\",\n",
        "    \"¿Cómo se relaciona la teoría de la información con el NLP?\",\n",
        "    \"Describe los desafíos del procesamiento de lenguaje natural\",\n",
        "    \"¿Qué es la generación de lenguaje natural y cómo se relaciona con NLP?\",\n",
        "    \"Explica el concepto de modelo de lenguaje en NLP\",\n",
        "    \"¿Cuál es la importancia de la pragmática en el procesamiento de lenguaje natural?\",\n",
        "\n",
        "    # ChromaDB (teoría)\n",
        "    \"Encuentra información detallada sobre el funcionamiento de BERT\",\n",
        "    \"Busca fragmentos que expliquen la arquitectura Transformer\",\n",
        "    \"Necesito teoría profunda sobre el modelo GPT\",\n",
        "    \"Dame información detallada sobre técnicas avanzadas de análisis de sentimientos\",\n",
        "    \"Busco explicaciones extensas sobre el funcionamiento de word2vec\",\n",
        "    \"Encuentra fragmentos que describan en detalle el proceso de named entity recognition\",\n",
        "    \"Necesito información completa sobre técnicas de resumen automático de texto\",\n",
        "    \"Busca teoría detallada sobre modelos de lenguaje neuronales\",\n",
        "    \"Dame explicaciones profundas sobre la traducción automática neuronal\",\n",
        "    \"Encuentra fragmentos que describan técnicas avanzadas de question answering\",\n",
        "    \"Busca información detallada sobre el funcionamiento de ELMo\",\n",
        "    \"Necesito una explicación profunda del mecanismo de atención en NLP\",\n",
        "    \"Encuentra fragmentos que describan en detalle las redes neuronales recurrentes en NLP\",\n",
        "    \"Dame información completa sobre el proceso de fine-tuning en modelos de lenguaje\",\n",
        "    \"Busco explicaciones detalladas sobre la arquitectura de las redes LSTM\",\n",
        "    \"Encuentra teoría profunda sobre el uso de transformers en NLP\",\n",
        "    \"Necesito información extensa sobre técnicas de transfer learning en procesamiento de lenguaje\",\n",
        "    \"Busca fragmentos que expliquen en detalle el funcionamiento de los autoencoders en NLP\",\n",
        "    \"Dame explicaciones detalladas sobre las técnicas de regularización en modelos de lenguaje\",\n",
        "    \"Encuentra información completa sobre la evaluación de modelos de NLP\",\n",
        "\n",
        "    # Más ejemplos mixtos\n",
        "    \"¿Cómo puedo implementar un clasificador de texto básico?\",\n",
        "    \"Explícame la diferencia entre supervisado y no supervisado en NLP\",\n",
        "    \"Necesito un ejercicio para practicar web scraping de texto\",\n",
        "    \"Busco información detallada sobre el funcionamiento de SpaCy\",\n",
        "    \"Dame un ejemplo de cómo usar regex en procesamiento de texto\",\n",
        "    \"¿Puedes explicarme qué es transfer learning en el contexto de NLP?\",\n",
        "    \"Quiero un ejercicio para practicar la creación de un chatbot simple\",\n",
        "    \"Encuentra información sobre las últimas tendencias en NLP\",\n",
        "    \"Necesito un ejercicio para practicar la generación de texto con GPT\",\n",
        "    \"Explícame en detalle cómo funciona la atención en los modelos Transformer\",\n",
        "    \"¿Cómo se implementa un sistema de recomendación basado en texto?\",\n",
        "    \"Dame ejemplos de aplicaciones de NLP en el mundo real\",\n",
        "    \"Necesito información sobre cómo manejar textos multilingües en NLP\",\n",
        "    \"Explícame las diferencias entre word2vec, GloVe y FastText\",\n",
        "    \"¿Cómo se puede usar NLP para el análisis de redes sociales?\",\n",
        "    \"Dame un ejercicio para practicar la detección de temas en un corpus de texto\",\n",
        "    \"Busco información sobre el uso de grafos de conocimiento en NLP\",\n",
        "    \"¿Cómo se puede implementar un corrector ortográfico usando NLP?\",\n",
        "    \"Necesito un ejercicio para practicar la generación de resúmenes de texto\",\n",
        "    \"Explícame cómo funciona la búsqueda semántica en NLP\",\n",
        "]\n",
        "\n",
        "categorias = [\n",
        "    \"csv\", \"csv\", \"csv\", \"csv\",\n",
        "    \"csv\", \"csv\", \"csv\", \"csv\", \"csv\",\n",
        "    \"csv\", \"csv\", \"csv\", \"csv\", \"csv\",\n",
        "    \"csv\", \"csv\", \"csv\", \"csv\", \"csv\",\n",
        "    \"grafo\", \"grafo\", \"grafo\", \"grafo\", \"grafo\",\n",
        "    \"grafo\", \"grafo\", \"grafo\", \"grafo\", \"grafo\",\n",
        "    \"grafo\", \"grafo\", \"grafo\", \"grafo\", \"grafo\",\n",
        "    \"grafo\", \"grafo\", \"grafo\", \"grafo\", \"grafo\",\n",
        "    \"chromadb\", \"chromadb\", \"chromadb\", \"chromadb\", \"chromadb\",\n",
        "    \"chromadb\", \"chromadb\", \"chromadb\", \"chromadb\", \"chromadb\",\n",
        "    \"chromadb\", \"chromadb\", \"chromadb\", \"chromadb\", \"chromadb\",\n",
        "    \"chromadb\", \"chromadb\", \"chromadb\", \"chromadb\", \"chromadb\",\n",
        "    \"csv\", \"grafo\", \"csv\", \"chromadb\", \"csv\",\n",
        "    \"chromadb\", \"csv\", \"chromadb\", \"csv\", \"chromadb\",\n",
        "    \"csv\", \"grafo\", \"chromadb\", \"chromadb\", \"grafo\",\n",
        "    \"csv\", \"grafo\", \"csv\", \"csv\", \"chromadb\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifUaAWlIKIgC"
      },
      "source": [
        "###### ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysNYoBnVjfhJ",
        "outputId": "a483ca60-0d33-4b98-bac0-3b2ebe067e23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Puntuaciones de validación cruzada: [1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1.\n",
            " 0. 1. 1. 0. 0. 1. 0.]\n",
            "Precisión media: 0.77 (+/- 0.84)\n",
            "\n",
            "Informe de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    chromadb       0.71      0.74      0.73        27\n",
            "         csv       0.89      0.86      0.87        28\n",
            "       grafo       0.71      0.71      0.71        24\n",
            "\n",
            "    accuracy                           0.77        79\n",
            "   macro avg       0.77      0.77      0.77        79\n",
            "weighted avg       0.77      0.77      0.77        79\n",
            "\n",
            "\n",
            "Para el prompt: 'Dame un ejercicio de codificación de archivos'\n",
            "La categoría predicha es: csv\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
        "from sklearn.metrics import classification_report, make_scorer, accuracy_score\n",
        "import joblib\n",
        "\n",
        "# Preparación de datos\n",
        "X = prompts\n",
        "y = categorias\n",
        "\n",
        "# Crear un pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', CountVectorizer(max_features=20)),  # Usar menos características\n",
        "    ('clf', MultinomialNB())  # Naive Bayes, un modelo simple\n",
        "])\n",
        "\n",
        "# Configurar la validación cruzada dejando uno fuera\n",
        "cv = LeaveOneOut()\n",
        "\n",
        "# Realizar validación cruzada\n",
        "scores = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy')\n",
        "\n",
        "print(\"Puntuaciones de validación cruzada:\", scores)\n",
        "print(\"Precisión media: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
        "\n",
        "# Función para obtener predicciones de validación cruzada\n",
        "def get_cv_predictions(model, X, y, cv):\n",
        "    y_pred = []\n",
        "    for train_index, test_index in cv.split(X):\n",
        "        X_train, X_test = [X[i] for i in train_index], [X[i] for i in test_index]\n",
        "        y_train, y_test = [y[i] for i in train_index], [y[i] for i in test_index]\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred.extend(model.predict(X_test))\n",
        "    return y_pred\n",
        "\n",
        "# Obtener predicciones de validación cruzada\n",
        "y_pred = get_cv_predictions(pipeline, X, y, cv)\n",
        "\n",
        "# Imprimir informe de clasificación\n",
        "print(\"\\nInforme de clasificación:\")\n",
        "print(classification_report(y, y_pred))\n",
        "\n",
        "# Entrenar el modelo final con todos los datos\n",
        "pipeline.fit(X, y)\n",
        "\n",
        "# Guardar el pipeline para uso futuro\n",
        "joblib.dump(pipeline, 'pipeline_clasificacion.joblib')\n",
        "\n",
        "# Función para predecir nuevos prompts\n",
        "def predecir_categoria(prompt):\n",
        "    return pipeline.predict([prompt])[0]\n",
        "\n",
        "# Vemos un ejemplo para ver como queda\n",
        "nuevo_prompt = \"Dame un ejercicio de codificación de archivos\"\n",
        "categoria_predicha = predecir_categoria(nuevo_prompt)\n",
        "print(f\"\\nPara el prompt: '{nuevo_prompt}'\")\n",
        "print(f\"La categoría predicha es: {categoria_predicha}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv6ouWOwae8D"
      },
      "source": [
        "# Clasificador basado en un modelo entrenado con ejemplos y embeddings (Unidad 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Xn1J0rFI7Y4q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.spatial.distance import cosine\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import joblib\n",
        "from functools import lru_cache\n",
        "\n",
        "# Cargar el modelo\n",
        "pipeline = joblib.load('pipeline_clasificacion.joblib')\n",
        "\n",
        "# Inicializar el vectorizador TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Definir el umbral de similitud\n",
        "UMBRAL_SIMILITUD = 0.6\n",
        "\n",
        "# Precalcular vectores TF-IDF para documentos conocidos\n",
        "def precalcular_tfidf():\n",
        "    global csv_vectors, grafo_vectors\n",
        "    csv_vectors = tfidf_vectorizer.fit_transform(ejercicios['Enunciado'])\n",
        "    grafo_vectors = tfidf_vectorizer.transform(list(G.nodes()))\n",
        "\n",
        "precalcular_tfidf()\n",
        "\n",
        "# Función para predecir la categoría\n",
        "@lru_cache(maxsize=1000)\n",
        "def predecir_categoria(prompt):\n",
        "    return pipeline.predict([prompt])[0]\n",
        "\n",
        "# Función para calcular la similitud coseno usando TF-IDF\n",
        "def tfidf_cosine_similarity(prompt_vector, doc_vector):\n",
        "    return 1 - cosine(prompt_vector.toarray()[0], doc_vector.toarray()[0])\n",
        "\n",
        "# Función para encontrar la respuesta más apropiada\n",
        "def encontrar_respuesta(prompt, categoria):\n",
        "    prompt_vector = tfidf_vectorizer.transform([prompt])\n",
        "\n",
        "    if categoria == 'csv':\n",
        "        similitudes = [tfidf_cosine_similarity(prompt_vector, doc_vector) for doc_vector in csv_vectors]\n",
        "        max_similitud = max(similitudes)\n",
        "        if max_similitud >= UMBRAL_SIMILITUD:\n",
        "            indice_mas_cercano = np.argmax(similitudes)\n",
        "            return ejercicios.iloc[indice_mas_cercano]['Enunciado']\n",
        "        else:\n",
        "            return f\"No se encontró información relevante sobre '{prompt}' en la categoría CSV.\"\n",
        "\n",
        "    elif categoria == 'grafo':\n",
        "        similitudes = [tfidf_cosine_similarity(prompt_vector, doc_vector) for doc_vector in grafo_vectors]\n",
        "        max_similitud = max(similitudes)\n",
        "        if max_similitud >= UMBRAL_SIMILITUD:\n",
        "            indice_mas_cercano = np.argmax(similitudes)\n",
        "            return list(G.nodes())[indice_mas_cercano]\n",
        "        else:\n",
        "            return f\"No se encontró información relevante sobre '{prompt}' en la categoría Grafo.\"\n",
        "\n",
        "    elif categoria == 'chromadb':\n",
        "        resultados = collection.query(\n",
        "            query_texts=[prompt],\n",
        "            n_results=1\n",
        "        )\n",
        "        if resultados['documents'] and resultados['distances'][0][0] <= (1 - UMBRAL_SIMILITUD):\n",
        "            return resultados['documents'][0][0]\n",
        "        else:\n",
        "            return f\"No se encontró información relevante sobre '{prompt}' en ChromaDB.\"\n",
        "\n",
        "# Función principal para procesar el prompt del usuario\n",
        "def procesar_prompt(prompt):\n",
        "    categoria = predecir_categoria(prompt)\n",
        "    respuesta = encontrar_respuesta(prompt, categoria)\n",
        "    return categoria, respuesta\n",
        "\n",
        "# Función para procesar múltiples prompts en lotes\n",
        "def procesar_prompts_en_lote(prompts):\n",
        "    categorias = [predecir_categoria(prompt) for prompt in prompts]\n",
        "    respuestas = [encontrar_respuesta(prompt, categoria) for prompt, categoria in zip(prompts, categorias)]\n",
        "    return list(zip(categorias, respuestas))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qL1xO2XDfaV",
        "outputId": "a2191d7f-6306-4dad-c99a-25fb88499ef8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt del usuario: 'Dame un ejercicio de codificación de archivos'\n",
            "Categoría predicha: csv\n",
            "Respuesta encontrada: No se encontró información relevante sobre 'Dame un ejercicio de codificación de archivos' en la categoría CSV.\n"
          ]
        }
      ],
      "source": [
        "prompt_usuario = \"Dame un ejercicio de codificación de archivos\"\n",
        "categoria, respuesta = procesar_prompt(prompt_usuario)\n",
        "\n",
        "print(f\"Prompt del usuario: '{prompt_usuario}'\")\n",
        "print(f\"Categoría predicha: {categoria}\")\n",
        "print(f\"Respuesta encontrada: {respuesta}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQEEmikZjnUs",
        "outputId": "421266df-701c-49e4-91da-3a35a9e93706"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt del usuario: 'Dame un ejercicio de audio'\n",
            "Categoría predicha: csv\n",
            "Respuesta encontrada: Obtenga texto de un archivo de audio.\n"
          ]
        }
      ],
      "source": [
        "prompt_usuario = \"Dame un ejercicio de audio\"\n",
        "categoria, respuesta = procesar_prompt(prompt_usuario)\n",
        "\n",
        "print(f\"Prompt del usuario: '{prompt_usuario}'\")\n",
        "print(f\"Categoría predicha: {categoria}\")\n",
        "print(f\"Respuesta encontrada: {respuesta}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRH1sIrkDg60",
        "outputId": "08aae573-cc00-4d19-bc7b-e535006571ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt del usuario: '¿Cómo podría obtener texto de un archivo Word utilizando Python?'\n",
            "Categoría predicha: csv\n",
            "Respuesta encontrada: Obtenga texto de un archivo word.\n"
          ]
        }
      ],
      "source": [
        "prompt_usuario = \"¿Cómo podría obtener texto de un archivo Word utilizando Python?\"\n",
        "categoria, respuesta = procesar_prompt(prompt_usuario)\n",
        "\n",
        "print(f\"Prompt del usuario: '{prompt_usuario}'\")\n",
        "print(f\"Categoría predicha: {categoria}\")\n",
        "print(f\"Respuesta encontrada: {respuesta}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pfjw-DbamPE"
      },
      "source": [
        "# Clasificador basado en LLM (Unidad 6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmVjc8iLEB86",
        "outputId": "a1abe4c3-65c4-4dfb-ef54-4fbe2aa50892"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt del usuario: Dame un ejercicio de codificación de archivos\n",
            "\n",
            "Base de datos utilizada: csv\n",
            "\n",
            "Respuesta: To encode a file in Python, you can use the built-in `base64` module. Here's an example:\n",
            "\n",
            "```python\n",
            "import base64\n",
            "\n",
            "# Open the file to be encoded\n",
            "with open('file.txt', 'rb') as file:\n",
            "    # Read the contents of the file\n",
            "    contents = file.read()\n",
            "\n",
            "# Encode the contents using base64\n",
            "encoded = base64.b64encode(contents)\n",
            "\n",
            "# Save the encoded file\n",
            "with open('encoded_file.txt', 'wb') as encoded_file:\n",
            "    encoded_file.write(encoded)\n",
            "```\n",
            "\n",
            "In this example, we first\n",
            "\n",
            "Métricas:\n",
            "tiempo_respuesta: 3.5300397872924805\n",
            "cantidad_tokens: 83\n",
            "\n",
            "==================================================\n",
            "\n",
            "Prompt del usuario: ¿Cómo podría obtener texto de un archivo Word utilizando Python?\n",
            "\n",
            "Base de datos utilizada: csv\n",
            "\n",
            "Respuesta: Para obtener texto de un archivo Word utilizando Python, puedes usar la biblioteca `PyWin32`. Primero, debes instalar esta biblioteca. Para ello, puedes ejecutar el siguiente comando en el terminal:\n",
            "\n",
            "```\n",
            "pip install pywin32\n",
            "```\n",
            "\n",
            "Luego, puedes escribir el siguiente código:\n",
            "\n",
            "```python\n",
            "import win32com.client as win32\n",
            "\n",
            "# Abrimos el archivo Word\n",
            "word = win32.gencache.EnvelopeDispatch(None, ('Word.Application',))\n",
            "document = word.Doc\n",
            "\n",
            "Métricas:\n",
            "tiempo_respuesta: 3.470088481903076\n",
            "cantidad_tokens: 76\n",
            "\n",
            "==================================================\n",
            "\n",
            "Prompt del usuario: ¿Podrías explicarme el concepto de RAG (Retrieval Augmented Generation)?\n",
            "\n",
            "Base de datos utilizada: grafo\n",
            "\n",
            "Respuesta: ¡Claro! El concepto de RAG (Retrieval Augmented Generation) se refiere a un método avanzado de generación de respuestas que combina la capacidad de recuperación de información y la generación de texto para proporcionar respuestas más precisas y relevantes. En otras palabras, RAG utiliza la capacidad de las redes neuronales para recuperar información relevante de una base de datos o corpus de texto, y luego genera una respuesta que incorpora esa información para proporcionar una respuesta más detallada y precisa que la simple gener\n",
            "\n",
            "Métricas:\n",
            "tiempo_respuesta: 3.363938331604004\n",
            "cantidad_tokens: 101\n",
            "\n",
            "==================================================\n",
            "\n",
            "Prompt del usuario: ¿Que es NLP?\n",
            "\n",
            "Base de datos utilizada: grafo\n",
            "\n",
            "Respuesta: NLP, o Processamiento del Lenguaje Natural, es un campo de investigación y desarrollo en la IA que se ocupa del procesamiento y análisis de lenguaje natural con el objetivo de permitir a las computadoras entender y procesar el lenguaje como lo hacen los seres humanos. Esto incluye la capacidad de leer, interpretar, generar y responder a textos, lo que permite la comunicación entre los humanos y las máquinas en una variedad de aplicaciones, desde la búsqueda de información hasta la generación automática de respuestas a preguntas. Al\n",
            "\n",
            "Métricas:\n",
            "tiempo_respuesta: 3.346835136413574\n",
            "cantidad_tokens: 99\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import chromadb\n",
        "import requests\n",
        "from decouple import config\n",
        "import sqlite3\n",
        "from time import time\n",
        "from google.colab import userdata\n",
        "\n",
        "# Función para consultar el grafo\n",
        "def query_graph(prompt):\n",
        "    relevant_nodes = []\n",
        "    for node in G.nodes():\n",
        "        if any(keyword in node.lower() for keyword in prompt.lower().split()):\n",
        "            relevant_nodes.append(node)\n",
        "            relevant_nodes.extend(list(G.neighbors(node)))\n",
        "\n",
        "    context = \"\"\n",
        "    for node in set(relevant_nodes):\n",
        "        context += f\"Concepto: {node}\\n\"\n",
        "        context += f\"Definición: {G.nodes[node].get('definicion', 'No disponible')}\\n\"\n",
        "        for neighbor in G.neighbors(node):\n",
        "            edge_data = G.get_edge_data(node, neighbor)\n",
        "            context += f\"- {edge_data['relacion']} {neighbor}\\n\"\n",
        "        context += \"\\n\"\n",
        "\n",
        "    return context\n",
        "\n",
        "# Función para consultar la base de datos tabular\n",
        "def query_tabular(prompt):\n",
        "    conn = sqlite3.connect(':memory:')\n",
        "    ejercicios.to_sql('ejercicios', conn, index=False)\n",
        "\n",
        "    cursor = conn.cursor()\n",
        "    query = f\"\"\"\n",
        "    SELECT Unidad, Tema, Tipo_Ejercicio, Enunciado, Dificultad\n",
        "    FROM ejercicios\n",
        "    WHERE Enunciado LIKE '%{prompt}%'\n",
        "    LIMIT 5\n",
        "    \"\"\"\n",
        "\n",
        "    results = cursor.execute(query).fetchall()\n",
        "    conn.close()\n",
        "\n",
        "    context = \"\"\n",
        "    for row in results:\n",
        "        context += f\"Unidad: {row[0]}, Tema: {row[1]}, Tipo: {row[2]}, Dificultad: {row[4]}\\n\"\n",
        "        context += f\"Enunciado: {row[3]}\\n\\n\"\n",
        "\n",
        "    return context\n",
        "\n",
        "# Función para consultar ChromaDB\n",
        "def query_chromadb(prompt):\n",
        "    results = collection.query(\n",
        "        query_texts=[prompt],\n",
        "        n_results=3\n",
        "    )\n",
        "\n",
        "    context = \"\"\n",
        "    for doc in results['documents'][0]:\n",
        "        context += doc + \"\\n\\n\"\n",
        "\n",
        "    return context\n",
        "\n",
        "def zephyr_chat_template(messages):\n",
        "    prompt = \"\"\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"system\":\n",
        "            prompt += f\"{message['content']}\\n\"\n",
        "        elif message[\"role\"] == \"user\":\n",
        "            prompt += f\"Usuario: {message['content']}\\n\"\n",
        "        elif message[\"role\"] == \"assistant\":\n",
        "            prompt += f\"Asistente: {message['content']}\\n\"\n",
        "    prompt += \"Asistente: \"\n",
        "    return prompt\n",
        "\n",
        "def prepare_prompt(query_str: str, context_str: str = \"\"):\n",
        "    text_qa_prompt_tmpl = (\n",
        "        \"Información de contexto:\\n\"\n",
        "        \"{context_str}\\n\"\n",
        "        \"Basándote en la información de contexto proporcionada, responde la siguiente pregunta en el mismo idioma que la pregunta:\\n\"\n",
        "        \"Pregunta: {query_str}\\n\"\n",
        "    )\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"Eres un asistente experto en Procesamiento del Lenguaje Natural. Responde siempre en el mismo idioma que la pregunta de manera útil, veraz y basada en datos.\"},\n",
        "        {\"role\": \"user\", \"content\": text_qa_prompt_tmpl.format(context_str=context_str, query_str=query_str)}\n",
        "    ]\n",
        "\n",
        "    return zephyr_chat_template(messages)\n",
        "\n",
        "def generate_response(prompt, max_new_tokens=150):\n",
        "    api_key = config('HF_TOKEN', default=userdata.get('HF_TOKEN'))\n",
        "    api_url = \"https://api-inference.huggingface.co/models/HuggingFaceH4/zephyr-7b-beta\"\n",
        "    headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
        "    data = {\n",
        "        \"inputs\": prompt,\n",
        "        \"parameters\": {\n",
        "            \"max_new_tokens\": max_new_tokens,\n",
        "            \"temperature\": 0.7,\n",
        "            \"top_k\": 50,\n",
        "            \"top_p\": 0.95\n",
        "        }\n",
        "    }\n",
        "\n",
        "    response = requests.post(api_url, headers=headers, json=data)\n",
        "    return response.json()[0]['generated_text'].split(\"Asistente: \")[-1].strip()\n",
        "\n",
        "def chatbot(user_prompt):\n",
        "    categoria = predecir_categoria(user_prompt)\n",
        "\n",
        "    if categoria == \"csv\":\n",
        "        context = query_tabular(user_prompt)\n",
        "    elif categoria == \"grafo\":\n",
        "        context = query_graph(user_prompt)\n",
        "    else:\n",
        "        context = query_chromadb(user_prompt)\n",
        "\n",
        "    full_prompt = prepare_prompt(user_prompt, context)\n",
        "    response = generate_response(full_prompt)\n",
        "\n",
        "    return f\"Prompt del usuario: {user_prompt}\\n\\n\" \\\n",
        "           f\"Base de datos utilizada: {categoria}\\n\\n\" \\\n",
        "           f\"Respuesta: {response}\"\n",
        "\n",
        "def calculate_metrics(start_time, end_time, user_prompt, response):\n",
        "    response_time = end_time - start_time\n",
        "    token_count = len(response.split())\n",
        "\n",
        "    return {\n",
        "        \"tiempo_respuesta\": response_time,\n",
        "        \"cantidad_tokens\": token_count,\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    queries = [\n",
        "        'Dame un ejercicio de codificación de archivos',\n",
        "        '¿Cómo podría obtener texto de un archivo Word utilizando Python?',\n",
        "        '¿Podrías explicarme el concepto de RAG (Retrieval Augmented Generation)?',\n",
        "        '¿Que es NLP?'\n",
        "    ]\n",
        "\n",
        "    for query in queries:\n",
        "        start_time = time()\n",
        "        result = chatbot(query)\n",
        "        end_time = time()\n",
        "\n",
        "        print(result)\n",
        "        print(\"\\nMétricas:\")\n",
        "        metrics = calculate_metrics(start_time, end_time, query, result)\n",
        "        for key, value in metrics.items():\n",
        "            print(f\"{key}: {value}\")\n",
        "        print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "_txXt-9EAWLo",
        "MTEpUB8VcqCi",
        "MxIPunB3jVSU",
        "RSamKWtfjXtS",
        "-buzJWEeKIgB",
        "ifUaAWlIKIgC"
      ],
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "064dbbd2131a45518fc66d3d6ef76746": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dd91c0fe4a4483380f4da2770076c39",
            "max": 134,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_37de6e3d25eb4ffc8ae9133109d667df",
            "value": 134
          }
        },
        "06752b86941e459dbda8e14574263044": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f526eaabee1413e9829bab4ef0b0589": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1009fac751e94809b256ba2f808c7be2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "120ece9b3f6446a593e111ed7a0389e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9201ef3d7a74f0c92ea44c45bf793f7",
            "placeholder": "​",
            "style": "IPY_MODEL_8f48b7f5ce3c4de581aa45ae1cb367ee",
            "value": "config.json: 100%"
          }
        },
        "14dceb684fc04aea9a13ec83c4768f91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f526eaabee1413e9829bab4ef0b0589",
            "placeholder": "​",
            "style": "IPY_MODEL_af86441c56884cc885110586ad66537f",
            "value": " 480k/480k [00:00&lt;00:00, 8.75MB/s]"
          }
        },
        "14df48dfa56f471db2e1ca4b43e2039f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15391e9e228a4d3f81be5f6b770ce404": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "171725987a2f473fb6c8935db2978325": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d245798eea2474a904928b46705ec66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e85e6d52787466d820bfd4d19ac4da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24482c08d1f34d56a859603e566e62e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24b637ac24c7460d844aed5d7ab39328": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27506c9e25d442869d6ffb308e3b46ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28bcb812edb741eba3d0c40253c10cd2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28ece375895643c7a5d1c016e7d57b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c66f9c4cfba4269bb7bd6ff0d35d11d",
            "placeholder": "​",
            "style": "IPY_MODEL_b1ae8c8c9d3b4a8288c844c3c976df9c",
            "value": "vocab.txt: 100%"
          }
        },
        "29094614d5654d2e92d42d80bee086dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1bd3f3814b14c3c85da38053bf4a353",
            "placeholder": "​",
            "style": "IPY_MODEL_fd1bb26e66774f88bff0575aba3bfbe8",
            "value": " 648/648 [00:00&lt;00:00, 37.4kB/s]"
          }
        },
        "2a1ef813c3c34e9aa9df65d2f276be4d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c82ff20fed042648f4f6cf8c62cbea1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d23793641794a9f9524901c1b04ce65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2dd91c0fe4a4483380f4da2770076c39": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30e529c3c9554adbad0b0844423dc70b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "37de6e3d25eb4ffc8ae9133109d667df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3cdfa2ac918143188e8005c9a91456d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24b637ac24c7460d844aed5d7ab39328",
            "placeholder": "​",
            "style": "IPY_MODEL_637085cdaccf457d9c0970807d881b5e",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "48474986230044c9b0426ba5e708e3c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5501b40abe9b4d629bf34ede2a3a8938": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8245d5ecaaf44746ba7f344b1bc433ef",
              "IPY_MODEL_6ece6c5b130b470c8ebdd13ad1adfe3c",
              "IPY_MODEL_c0b47ce6857445f787bbc144b56b9bd0"
            ],
            "layout": "IPY_MODEL_24482c08d1f34d56a859603e566e62e6"
          }
        },
        "5a012b5384f14c3394098900badc6116": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62b764b18ca64bfc8c224b3ed62e42b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bfb779f85c04f2fa9ff29d98a03431c",
            "placeholder": "​",
            "style": "IPY_MODEL_752d15670b3546b4a1dead2e36268b2c",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "637085cdaccf457d9c0970807d881b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65db3677eba344e9b345cb18a5aa5414": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1009fac751e94809b256ba2f808c7be2",
            "max": 364,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dde79e958c5b4f6482a5069fce47f179",
            "value": 364
          }
        },
        "6cdd667abaaf443994877301a5341e0a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e842712cfa34092b946ec2aca4305db": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ece6c5b130b470c8ebdd13ad1adfe3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e842712cfa34092b946ec2aca4305db",
            "max": 439621341,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06752b86941e459dbda8e14574263044",
            "value": 439621341
          }
        },
        "74b01fa8c21f4b199144c4ffaf4a27cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a00ddb43af5c4d1d99cf5c0f42ec5bb5",
            "placeholder": "​",
            "style": "IPY_MODEL_171725987a2f473fb6c8935db2978325",
            "value": " 364/364 [00:00&lt;00:00, 13.3kB/s]"
          }
        },
        "752d15670b3546b4a1dead2e36268b2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76953c74e0ea426b8a74ebb0484410b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62b764b18ca64bfc8c224b3ed62e42b0",
              "IPY_MODEL_65db3677eba344e9b345cb18a5aa5414",
              "IPY_MODEL_74b01fa8c21f4b199144c4ffaf4a27cf"
            ],
            "layout": "IPY_MODEL_28bcb812edb741eba3d0c40253c10cd2"
          }
        },
        "7c66f9c4cfba4269bb7bd6ff0d35d11d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f214add7db2461a8cc243c48bbfa3d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_120ece9b3f6446a593e111ed7a0389e0",
              "IPY_MODEL_bf7554ffbb2a47cea5d09e7685dd0ccd",
              "IPY_MODEL_29094614d5654d2e92d42d80bee086dd"
            ],
            "layout": "IPY_MODEL_cfdb4221714c46eb876416aab103ca86"
          }
        },
        "8245d5ecaaf44746ba7f344b1bc433ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48474986230044c9b0426ba5e708e3c2",
            "placeholder": "​",
            "style": "IPY_MODEL_14df48dfa56f471db2e1ca4b43e2039f",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "83578b93d5e04ad18d2d073585d656c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a1ef813c3c34e9aa9df65d2f276be4d",
            "placeholder": "​",
            "style": "IPY_MODEL_15391e9e228a4d3f81be5f6b770ce404",
            "value": " 134/134 [00:00&lt;00:00, 7.83kB/s]"
          }
        },
        "8bfb779f85c04f2fa9ff29d98a03431c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c592e06559a40fe8fd6d795a9ab4d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cdd667abaaf443994877301a5341e0a",
            "max": 480199,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30e529c3c9554adbad0b0844423dc70b",
            "value": 480199
          }
        },
        "8edcf04be9e84d76b7a153a67c69914e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f48b7f5ce3c4de581aa45ae1cb367ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a00ddb43af5c4d1d99cf5c0f42ec5bb5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af86441c56884cc885110586ad66537f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1ae8c8c9d3b4a8288c844c3c976df9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6773f485cb94be3b6a78ee48f9a37c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3cdfa2ac918143188e8005c9a91456d9",
              "IPY_MODEL_064dbbd2131a45518fc66d3d6ef76746",
              "IPY_MODEL_83578b93d5e04ad18d2d073585d656c8"
            ],
            "layout": "IPY_MODEL_d273411970d949a98ec430c8db5f40c9"
          }
        },
        "bf7554ffbb2a47cea5d09e7685dd0ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfb7f1b0e7a540d1bff6b613679855bd",
            "max": 648,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cbbd93622a8b455da0caf202f5a0ecea",
            "value": 648
          }
        },
        "c0369ffe0a48470183e5e6bda13deb66": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0b47ce6857445f787bbc144b56b9bd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0369ffe0a48470183e5e6bda13deb66",
            "placeholder": "​",
            "style": "IPY_MODEL_2d23793641794a9f9524901c1b04ce65",
            "value": " 440M/440M [00:07&lt;00:00, 71.7MB/s]"
          }
        },
        "c0f1f62724db451a9367649c9b962b9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a012b5384f14c3394098900badc6116",
            "max": 241796,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6a5cc7de17c46f5b1f6aebbc5691d99",
            "value": 241796
          }
        },
        "c9201ef3d7a74f0c92ea44c45bf793f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca8e309cf0f34941b2938d5f3cf090cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d31a0e4e4a2f457c92780eda0c104060",
              "IPY_MODEL_8c592e06559a40fe8fd6d795a9ab4d75",
              "IPY_MODEL_14dceb684fc04aea9a13ec83c4768f91"
            ],
            "layout": "IPY_MODEL_eb65f2594a3046c6a514b62377b24b54"
          }
        },
        "cbbd93622a8b455da0caf202f5a0ecea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cfdb4221714c46eb876416aab103ca86": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d25c9af0a86f4f3cb27fa0c6f4d4ba1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27506c9e25d442869d6ffb308e3b46ae",
            "placeholder": "​",
            "style": "IPY_MODEL_1d245798eea2474a904928b46705ec66",
            "value": " 242k/242k [00:00&lt;00:00, 3.27MB/s]"
          }
        },
        "d273411970d949a98ec430c8db5f40c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d31a0e4e4a2f457c92780eda0c104060": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8edcf04be9e84d76b7a153a67c69914e",
            "placeholder": "​",
            "style": "IPY_MODEL_1e85e6d52787466d820bfd4d19ac4da3",
            "value": "tokenizer.json: 100%"
          }
        },
        "dde79e958c5b4f6482a5069fce47f179": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dfb7f1b0e7a540d1bff6b613679855bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1bd3f3814b14c3c85da38053bf4a353": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6a5cc7de17c46f5b1f6aebbc5691d99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb65f2594a3046c6a514b62377b24b54": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9065a567c134e76b291875be6e287ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28ece375895643c7a5d1c016e7d57b40",
              "IPY_MODEL_c0f1f62724db451a9367649c9b962b9e",
              "IPY_MODEL_d25c9af0a86f4f3cb27fa0c6f4d4ba1a"
            ],
            "layout": "IPY_MODEL_2c82ff20fed042648f4f6cf8c62cbea1"
          }
        },
        "fd1bb26e66774f88bff0575aba3bfbe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
